<!doctype html>
<html class="theme-next use-motion theme-next-mist">
<head>
  

<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />








  <link rel="stylesheet" type="text/css" href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5"/>




<link rel="stylesheet" type="text/css" href="/css/main.css?v=0.4.5.1"/>


    <meta name="description" content="Spring Boot 分布式技术博客" />



  <meta name="keywords" content="Hexo,next" />





  <link rel="shorticon icon" type="image/x-icon" href="/favicon.ico?v=0.4.5.1" />


<meta name="description" content="Spring Boot 分布式技术博客">
<meta property="og:type" content="website">
<meta property="og:title" content="泽睿的自言自语">
<meta property="og:url" content="http://boot.ren/index.html">
<meta property="og:site_name" content="泽睿的自言自语">
<meta property="og:description" content="Spring Boot 分布式技术博客">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="泽睿的自言自语">
<meta name="twitter:description" content="Spring Boot 分布式技术博客">


<script type="text/javascript" id="hexo.configuration">
  var CONFIG = {
    scheme: 'Mist',
    sidebar: 'post'
  };
</script>

  <title> 泽睿的自言自语 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  <!--[if lte IE 8]>
  <div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;margin:0 auto;'>
    <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode">
      <img src="http://7u2nvr.com1.z0.glb.clouddn.com/picouterie.jpg" border="0" height="42" width="820"
           alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today or use other browser ,like chrome firefox safari."
           style='margin-left:auto;margin-right:auto;display: block;'/>
    </a>
  </div>
<![endif]-->
  



  <div class="container one-column 
   page-home 
">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><h1 class="site-meta">
  <span class="logo-line-before"><i></i></span>
  <a href="/" class="brand" rel="start">
      <span class="logo">
        <i class="icon-next-logo"></i>
      </span>
      <span class="site-title">泽睿的自言自语</span>
  </a>
  <span class="logo-line-after"><i></i></span>
</h1>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu ">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            <i class="menu-item-icon icon-next-home"></i> <br />
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            <i class="menu-item-icon icon-next-archives"></i> <br />
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            <i class="menu-item-icon icon-next-tags"></i> <br />
            标签
          </a>
        </li>
      

      
      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div id="content" class="content"> 
  <section id="posts" class="posts-expand">
    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2016/01/20/nginx配置location总结及rewrite规则写法/" itemprop="url">
                nginx配置location总结及rewrite规则写法
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2016-01-20T13:20:49+08:00" content="2016-01-20">
            2016-01-20
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2016/01/20/nginx配置location总结及rewrite规则写法/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2016/01/20/nginx配置location总结及rewrite规则写法/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><h1 id="location正则写法">location正则写法</h1><p>示例:<br><figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="xml">location  = / </span><span class="expression">&#123;</span><br><span class="line">  <span class="begin-block"># </span>精确匹配 <span class="end-block">/ </span>，主机名后面不能带任何字符串</span><br><span class="line">  [ <span class="variable">configuration</span> <span class="variable">A</span> ] </span><br><span class="line">&#125;</span><span class="xml"></span><br><span class="line">location  / </span><span class="expression">&#123;</span><br><span class="line">  <span class="begin-block"># </span>因为所有的地址都以 <span class="end-block">/ </span>开头，所以这条规则将匹配到所有请求</span><br><span class="line">  <span class="begin-block"># </span>但是正则和最长字符串会优先匹配</span><br><span class="line">  [ <span class="variable">configuration</span> <span class="variable">B</span> ] </span><br><span class="line">&#125;</span><span class="xml"></span><br><span class="line">location /documents/ </span><span class="expression">&#123;</span><br><span class="line">  <span class="begin-block"># </span>匹配任何以 <span class="end-block">/documents</span><span class="end-block">/ </span>开头的地址，匹配符合以后，还要继续往下搜索</span><br><span class="line">  <span class="begin-block"># </span>只有后面的正则表达式没有匹配到时，这一条才会采用这一条</span><br><span class="line">  [ <span class="variable">configuration</span> <span class="variable">C</span> ] </span><br><span class="line">&#125;</span><span class="xml"></span><br><span class="line">location ~ /documents/Abc </span><span class="expression">&#123;</span><br><span class="line">  <span class="begin-block"># </span>匹配任何以 <span class="end-block">/documents</span><span class="end-block">/ </span>开头的地址，匹配符合以后，还要继续往下搜索</span><br><span class="line">  <span class="begin-block"># </span>只有后面的正则表达式没有匹配到时，这一条才会采用这一条</span><br><span class="line">  [ <span class="variable">configuration</span> <span class="variable">CC</span> ] </span><br><span class="line">&#125;</span><span class="xml"></span><br><span class="line">location ^~ /images/ </span><span class="expression">&#123;</span><br><span class="line">  <span class="begin-block"># </span>匹配任何以 <span class="end-block">/images</span><span class="end-block">/ </span>开头的地址，匹配符合以后，停止往下搜索正则，采用这一条。</span><br><span class="line">  [ <span class="variable">configuration</span> <span class="variable">D</span> ] </span><br><span class="line">&#125;</span><span class="xml"></span><br><span class="line">location ~* \.(gif|jpg|jpeg)$ </span><span class="expression">&#123;</span><br><span class="line">  <span class="begin-block"># </span>匹配所有以 <span class="variable">gif</span>,<span class="variable">jpg</span>或<span class="variable">jpeg</span> 结尾的请求</span><br><span class="line">  <span class="begin-block"># </span>然而，所有请求 <span class="end-block">/images</span><span class="end-block">/ </span>下的图片会被 <span class="variable">config</span> <span class="variable">D</span> 处理，因为 ^~ 到达不了这一条正则</span><br><span class="line">  [ <span class="variable">configuration</span> <span class="variable">E</span> ] </span><br><span class="line">&#125;</span><span class="xml"></span><br><span class="line">location /images/ </span><span class="expression">&#123;</span><br><span class="line">  <span class="begin-block"># </span>字符匹配到 <span class="end-block">/images</span>/，继续往下，会发现 ^~ 存在</span><br><span class="line">  [ <span class="variable">configuration</span> <span class="variable">F</span> ] </span><br><span class="line">&#125;</span><span class="xml"></span><br><span class="line">location /images/abc </span><span class="expression">&#123;</span><br><span class="line">  <span class="begin-block"># </span>最长字符匹配到 <span class="end-block">/images</span><span class="end-block">/abc</span>，继续往下，会发现 ^~ 存在</span><br><span class="line">  <span class="begin-block"># F</span>与<span class="variable">G</span>的放置顺序是没有关系的</span><br><span class="line">  [ <span class="variable">configuration</span> <span class="variable">G</span> ] </span><br><span class="line">&#125;</span><span class="xml"></span><br><span class="line">location ~ /images/abc/ </span><span class="expression">&#123;</span><br><span class="line">  <span class="begin-block"># </span>只有去掉 <span class="variable">config</span> <span class="variable">D</span> 才有效：先最长匹配 <span class="variable">config</span> <span class="variable">G</span> 开头的地址，继续往下搜索，匹配到这一条正则，采用</span><br><span class="line">    [ <span class="variable">configuration</span> <span class="variable">H</span> ] </span><br><span class="line">&#125;</span><span class="xml"></span><br><span class="line">location ~* /js/.*/\.js</span></span><br></pre></td></tr></table></figure></p>
<ul>
<li>已=开头表示精确匹配  如 A 中只匹配根目录结尾的请求，后面不能带任何字符串。</li>
<li>^~ 开头表示uri以某个常规字符串开头，不是正则匹配</li>
<li>~ 开头表示区分大小写的正则匹配;</li>
<li>~* 开头表示不区分大小写的正则匹配</li>
<li>/ 通用匹配, 如果没有其它匹配,任何请求都会匹配到</li>
</ul>
<blockquote>
<p>顺序 no优先级：(location =) &gt; (location 完整路径) &gt; (location ^~ 路径) &gt; (location ~,~* 正则顺序) &gt; (location 部分起始路径) &gt; (/)</p>
</blockquote>
<p>上面的匹配结果<br>按照上面的location写法，以下的匹配示例成立：</p>
<ul>
<li>/ -&gt; config A精确完全匹配，即使/index.html也匹配不了</li>
<li>/downloads/download.html -&gt; config B匹配B以后，往下没有任何匹配，采用B</li>
<li>/images/1.gif -&gt; configuration D匹配到F，往下匹配到D，停止往下</li>
<li>/images/abc/def -&gt; config D最长匹配到G，往下匹配D，停止往下你可以看到 任何以/images/开头的都会匹配到D并停止，FG写在这里是没有任何意义的，H是永远轮不到的，这里只是为了说明匹配顺序</li>
<li>/documents/document.html -&gt; config C匹配到C，往下没有任何匹配，采用C</li>
<li>/documents/1.jpg -&gt; configuration E匹配到C，往下正则匹配到E</li>
<li>/documents/Abc.jpg -&gt; config CC最长匹配到C，往下正则顺序匹配到CC，不会往下到E</li>
</ul>
<h1 id="实际使用建议">实际使用建议</h1><figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">所以实际使用中，个人觉得至少有三个匹配规则定义，如下：</span><br><span class="line"><span class="preprocessor">#直接匹配网站根，通过域名访问网站首页比较频繁，使用这个会加速处理，官网如是说。</span></span><br><span class="line"><span class="preprocessor">#这里是直接转发给后端应用服务器了，也可以是一个静态首页</span></span><br><span class="line"><span class="preprocessor"># 第一个必选规则</span></span><br><span class="line">location = / &#123;</span><br><span class="line">    proxy_pass http:<span class="comment">//tomcat:8080/index</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="preprocessor"># 第二个必选规则是处理静态文件请求，这是nginx作为http服务器的强项</span></span><br><span class="line"><span class="preprocessor"># 有两种配置模式，目录匹配或后缀匹配,任选其一或搭配使用</span></span><br><span class="line">location ^~ /<span class="keyword">static</span>/ &#123;</span><br><span class="line">    root /webroot/<span class="keyword">static</span>/;</span><br><span class="line">&#125;</span><br><span class="line">location ~* \.(gif|jpg|jpeg|png|css|js|ico)$ &#123;</span><br><span class="line">    root /webroot/res/;</span><br><span class="line">&#125;</span><br><span class="line"><span class="preprocessor">#第三个规则就是通用规则，用来转发动态请求到后端应用服务器</span></span><br><span class="line"><span class="preprocessor">#非静态文件请求就默认是动态请求，自己根据实际把握</span></span><br><span class="line"><span class="preprocessor">#毕竟目前的一些框架的流行，带.php,.jsp后缀的情况很少了</span></span><br><span class="line">location / &#123;</span><br><span class="line">    proxy_pass http:<span class="comment">//tomcat:8080/</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>参考:<br><a href="http://tengine.taobao.org/book/chapter_02.html" target="_blank" rel="external">http://tengine.taobao.org/book/chapter_02.html</a><br><a href="http://nginx.org/en/docs/http/ngx_http_rewrite_module.html" target="_blank" rel="external">http://nginx.org/en/docs/http/ngx_http_rewrite_module.html</a></p>
<h1 id="Rewrite规则">Rewrite规则</h1><p>rewrite功能就是，使用nginx提供的全局变量或自己设置的变量，结合正则表达式和标志位实现url重写以及重定向。rewrite只能放在server{},location{},if{}中，并且只能对域名后边的除去传递的参数外的字符串起作用，例如 <a href="http://seanlook.com/a/we/index.php?id=1&amp;u=str" target="_blank" rel="external">http://seanlook.com/a/we/index.php?id=1&amp;u=str</a> 只对/a/we/index.php重写。语法rewrite regex replacement [flag];</p>
<p>如果相对域名或参数字符串起作用，可以使用全局变量匹配，也可以使用proxy_pass反向代理。</p>
<p>表明看rewrite和location功能有点像，都能实现跳转，主要区别在于rewrite是在同一域名内更改获取资源的路径，而location是对一类路径做控制访问或反向代理，可以proxy_pass到其他机器。很多情况下rewrite也会写在location里，它们的执行顺序是：</p>
<ul>
<li>执行server块的rewrite指令</li>
<li>执行location匹配</li>
<li>执行选定的location中的rewrite指令</li>
</ul>
<p>如果其中某步URI被重写，则重新循环执行1-3，直到找到真实存在的文件；循环超过10次，则返回500 Internal Server Error错误。</p>
<h2 id="flag标志位">flag标志位</h2><ul>
<li>last : 相当于Apache的[L]标记，表示完成rewrite</li>
<li>break : 停止执行当前虚拟主机的后续rewrite指令集</li>
<li>redirect : 返回302临时重定向，地址栏会显示跳转后的地址</li>
<li>permanent : 返回301永久重定向，地址栏会显示跳转后的地址</li>
</ul>
<blockquote>
<p>因为301和302不能简单的只返回状态码，还必须有重定向的URL，这就是return指令无法返回301,302的原因了。这里 last 和 break 区别有点难以理解：</p>
</blockquote>
<ul>
<li>last一般写在server和if中，而break一般使用在location中</li>
<li>last不终止重写后的url匹配，即新的url会再从server走一遍匹配流程，而break终止重写后的匹配</li>
<li>break和last都能组织继续执行后面的rewrite指令</li>
</ul>
<h2 id="if指令与全局变量">if指令与全局变量</h2><p>if判断指令<br>语法为if(condition){…}，对给定的条件condition进行判断。如果为真，大括号内的rewrite指令将被执行，if条件(conditon)可以是如下任何内容：</p>
<ul>
<li>当表达式只是一个变量时，如果值为空或任何以0开头的字符串都会当做false</li>
<li>直接比较变量和内容时，使用=或!=</li>
<li>~正则表达式匹配，~*不区分大小写的匹配，!~区分大小写的不匹配</li>
</ul>
<pre><code>-<span class="ruby">f和!-f用来判断是否存在文件
</span>-<span class="ruby">d和!-d用来判断是否存在目录
</span>-<span class="ruby">e和!-e用来判断是否存在文件或目录
</span>-<span class="ruby">x和!-x用来判断文件是否可执行</span>
</code></pre><p>例如:</p>
<figure class="highlight xquery"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (<span class="variable">$http</span>_user_agent ~ MSIE) &#123;</span><br><span class="line">    rewrite ^(.*)$ /msie/<span class="variable">$1</span> break;</span><br><span class="line">&#125; //如果UA包含<span class="string">"MSIE"</span>，rewrite请求到/msid/目录下</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$http</span>_cookie ~* <span class="string">"id=([^;]+)(?:;|$)"</span>) &#123;</span><br><span class="line">    set <span class="variable">$id</span> <span class="variable">$1</span>;</span><br><span class="line"> &#125; //如果cookie匹配正则，设置变量<span class="variable">$id</span>等于正则引用部分</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$request</span>_method = POST) &#123;</span><br><span class="line">    return <span class="number">405</span>;</span><br><span class="line">&#125; //如果提交方法为POST，则返回状态<span class="number">405</span>（Method not allowed）。<span class="keyword">return</span>不能返回<span class="number">301</span>,<span class="number">302</span></span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$slow</span>) &#123;</span><br><span class="line">    limit_rate <span class="number">10</span>k;</span><br><span class="line">&#125; //限速，<span class="variable">$slow</span>可以通过 set 指令设置</span><br><span class="line"><span class="keyword">if</span> (!-f <span class="variable">$request</span>_filename)&#123;</span><br><span class="line">    break;</span><br><span class="line">    proxy_pass  http://<span class="number">127.0</span>.<span class="number">0</span>.<span class="number">1</span>; </span><br><span class="line">&#125; //如果请求的文件名不存在，则反向代理到localhost 。这里的break也是停止rewrite检查</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$args</span> ~ post=<span class="number">140</span>)&#123;</span><br><span class="line">    rewrite ^ http://example.com/ permanent;</span><br><span class="line">&#125; //如果query string中包含<span class="string">"post=140"</span>，永久重定向到example.com</span><br><span class="line">location ~* \.(gif|jpg|png|swf|flv)$ &#123;</span><br><span class="line">    valid_referers none blocked www.jefflei.com www.leizhenfang.com;</span><br><span class="line">    if (<span class="variable">$invalid</span>_referer) &#123;</span><br><span class="line">        return <span class="number">404</span>;</span><br><span class="line">    &#125; //防盗链</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>全局变量<br>下面是可以用作if判断的全局变量</p>
<ul>
<li>$args ： #这个变量等于请求行中的参数，同$query_string</li>
<li>$content_length ： 请求头中的Content-length字段。</li>
<li>$content_type ： 请求头中的Content-Type字段。</li>
<li>$document_root ： 当前请求在root指令中指定的值。</li>
<li>$host ： 请求主机头字段，否则为服务器名称。</li>
<li>$http_user_agent ： 客户端agent信息</li>
<li>$http_cookie ： 客户端cookie信息</li>
<li>$limit_rate ： 这个变量可以限制连接速率。</li>
<li>$request_method ： 客户端请求的动作，通常为GET或POST。</li>
<li>$remote_addr ： 客户端的IP地址。</li>
<li>$remote_port ： 客户端的端口。</li>
<li>$remote_user ： 已经经过Auth Basic Module验证的用户名。</li>
<li>$request_filename ： 当前请求的文件路径，由root或alias指令与URI请求生成。</li>
<li>$scheme ： HTTP方法（如http，https）。</li>
<li>$server_protocol ： 请求使用的协议，通常是HTTP/1.0或HTTP/1.1。</li>
<li>$server_addr ： 服务器地址，在完成一次系统调用后可以确定这个值。</li>
<li>$server_name ： 服务器名称。</li>
<li>$server_port ： 请求到达服务器的端口号。</li>
<li>$request_uri ： 包含请求参数的原始URI，不包含主机名，如：”/foo/bar.php?arg=baz”。</li>
<li>$uri ： 不带请求参数的当前URI，$uri不包含主机名，如”/foo/bar.html”。</li>
<li>$document_uri ： 与$uri相同。</li>
</ul>
<p>例：<a href="http://localhost:88/test1/test2/test.php" target="_blank" rel="external">http://localhost:88/test1/test2/test.php</a></p>
<p>$host：localhost<br>$server_port：88<br>$request_uri：<a href="http://localhost:88/test1/test2/test.php" target="_blank" rel="external">http://localhost:88/test1/test2/test.php</a><br>$document_uri：/test1/test2/test.php<br>$document_root：/var/www/html<br>$request_filename：/var/www/html/test1/test2/test.php</p>
<h1 id="常用正则">常用正则</h1><ul>
<li>. ： 匹配除换行符以外的任意字符</li>
<li>? ： 重复0次或1次</li>
<li><ul>
<li>： 重复1次或更多次</li>
</ul>
</li>
<li><ul>
<li>： 重复0次或更多次</li>
</ul>
</li>
<li>\d ：匹配数字</li>
<li>^ ： 匹配字符串的开始</li>
<li>$ ： 匹配字符串的介绍</li>
<li>{n} ： 重复n次</li>
<li>{n,} ： 重复n次或更多次</li>
<li>[c] ： 匹配单个字符c</li>
<li>[a-z] ： 匹配a-z小写字母的任意一个</li>
</ul>
<p>小括号()之间匹配的内容，可以在后面通过$1来引用，$2表示的是前面第二个()里的内容。正则里面容易让人困惑的是\转义特殊字符。</p>
<h1 id="rewrite实例">rewrite实例</h1><p>例1:<br><figure class="highlight xquery"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">    # 定义image日志格式</span><br><span class="line">    log_format imagelog <span class="string">'[$time_local] '</span> <span class="variable">$image</span>_file <span class="string">' '</span> <span class="variable">$image</span>_type <span class="string">' '</span> <span class="variable">$body</span>_bytes_sent <span class="string">' '</span> <span class="variable">$status</span>;</span><br><span class="line">    # 开启重写日志</span><br><span class="line">    rewrite_log on;</span><br><span class="line"> </span><br><span class="line">    server &#123;</span><br><span class="line">        root /home/www;</span><br><span class="line"> </span><br><span class="line">        location / &#123;</span><br><span class="line">                # 重写规则信息</span><br><span class="line">                error_log logs/rewrite.log notice; </span><br><span class="line">                # 注意这里要用‘’单引号引起来，避免&#123;&#125;</span><br><span class="line">                rewrite <span class="string">'^/images/([a-z]&#123;2&#125;)/([a-z0-9]&#123;5&#125;)/(.*)\.(png|jpg|gif)$'</span> /data?file=<span class="variable">$3</span>.<span class="variable">$4</span>;</span><br><span class="line">                # 注意不能在上面这条规则后面加上“last”参数，否则下面的set指令不会执行</span><br><span class="line">                set <span class="variable">$image</span>_file <span class="variable">$3</span>;</span><br><span class="line">                set <span class="variable">$image</span>_type <span class="variable">$4</span>;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        location /data &#123;</span><br><span class="line">                # 指定针对图片的日志格式，来分析图片类型和大小</span><br><span class="line">                access_log logs/images.log mian;</span><br><span class="line">                root /data/images;</span><br><span class="line">                # 应用前面定义的变量。判断首先文件在不在，不在再判断目录在不在，如果还不在就跳转到最后一个url里</span><br><span class="line">                try_files /<span class="variable">$arg</span>_file /image404.html;</span><br><span class="line">        &#125;</span><br><span class="line">        location = /image404.html &#123;</span><br><span class="line">                # 图片不存在返回特定的信息</span><br><span class="line">                return <span class="number">404</span> <span class="string">"image not found\n"</span>;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>对形如/images/ef/uh7b3/test.png的请求，重写到/data?file=test.png，于是匹配到location /data，先看/data/images/test.png文件存不存在，如果存在则正常响应，如果不存在则重写tryfiles到新的image404 location，直接返回404状态码。</p>
<p>例2:<br><figure class="highlight xquery"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rewrite ^/images/(.*)<span class="number">_</span>(\d+)x(\d+)\.(png|jpg|gif)$ /resizer/<span class="variable">$1</span>.<span class="variable">$4</span>?width=<span class="variable">$2</span>&amp;height=<span class="variable">$3</span>? last;</span><br></pre></td></tr></table></figure></p>
<p>对形如/images/bla_500x400.jpg的文件请求，重写到/resizer/bla.jpg?width=500&amp;height=400地址，并会继续尝试匹配location。</p>
<p>例3:</p>
<p>见 <a href="http://seanlook.com/2015/05/28/nginx-ssl" target="_blank" rel="external">ssl部分页面加密</a> 。</p>
<p>参考<br><a href="http://www.nginx.cn/216.html" target="_blank" rel="external">http://www.nginx.cn/216.html</a><br><a href="http://www.ttlsa.com/nginx/nginx-rewriting-rules-guide/" target="_blank" rel="external">http://www.ttlsa.com/nginx/nginx-rewriting-rules-guide/</a></p>
<p>老僧系列nginx之rewrite规则快速上手<br><a href="http://fantefei.blog.51cto.com/2229719/919431" target="_blank" rel="external">http://fantefei.blog.51cto.com/2229719/919431</a></p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2016/01/14/TCP-IP-WebSocket和MQTT/" itemprop="url">
                TCP/IP,WebSocket和MQTT
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2016-01-14T23:19:01+08:00" content="2016-01-14">
            2016-01-14
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2016/01/14/TCP-IP-WebSocket和MQTT/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2016/01/14/TCP-IP-WebSocket和MQTT/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><blockquote>
<p>按照OSI网络分层模型，IP是网络层协议，TCP是传输层协议，而HTTP和MQTT是应用层的协议。在这三者之间， TCP是HTTP和MQTT底层的协议。大家对HTTP很熟悉，这里简要介绍下MQTT。MQTT（Message Queuing Telemetry Transport，消息队列遥测传输）是IBM开发的一个即时通讯协议，有可能成为物联网的重要组成部分。该协议支持所有平台，几乎可以把所有联网物品和外部连接起来，被用来当做传感器的通信协议。</p>
</blockquote>
<h1 id="HTTP的不足">HTTP的不足</h1><p>HTTP协议经过多年的使用，发现了一些不足，主要是性能方面的，包括：</p>
<p>HTTP的连接问题，HTTP客户端和服务器之间的交互是采用请求/应答模式，在客户端请求时，会建立一个HTTP连接，然后发送请求消息，服务端给出应答消息，然后连接就关闭了。（后来的HTTP1.1支持持久连接）<br>因为TCP连接的建立过程是有开销的，如果使用了SSL/TLS开销就更大。</p>
<p>在浏览器里，一个网页包含许多资源，包括HTML，CSS，JavaScript，图片等等，这样在加载一个网页时要同时打开连接到同一服务器的多个连接。</p>
<p>HTTP消息头问题，现在的客户端会发送大量的HTTP消息头，由于一个网页可能需要50-100个请求，就会有相当大的消息头的数据量。</p>
<p>HTTP通信方式问题，HTTP的请求/应答方式的会话都是客户端发起的，缺乏服务器通知客户端的机制，在需要通知的场景，如聊天室，游戏，客户端应用需要不断地轮询服务器。</p>
<p>而 WebSocket是从不同的角度来解决这些不足中的一部分。还有其他技术也在针对这些不足提出改进。</p>
<h1 id="WebSocket">WebSocket</h1><p>WebSocket则提供使用一个TCP连接进行双向通讯的机制，包括网络协议和API，以取代网页和服务器采用HTTP轮询进行双向通讯的机制。<br>本质上来说，WebSocket是不限于HTTP协议的，但是由于现存大量的HTTP基础设施，代理，过滤，身份认证等等，WebSocket借用HTTP和HTTPS的端口。由于使用HTTP的端口，因此TCP连接建立后的握手消息是基于HTTP的，由服务器判断这是一个HTTP协议，还是WebSocket协议。 WebSocket连接除了建立和关闭时的握手，数据传输和HTTP没丁点关系了。</p>
<p>历时11年，WebSocket终于被批准成为IETF的建议标准：RFC6455.其前身是WHATWG （Web Hypertext Application Technology Working Group）的工作。而Web Socket的API,是W3C的工作。</p>
<p>WebSocket可以只打开一个到服务器的链接，并且在此链接上交换信息。其优势在于减少了传统方法的复杂性，提高了可靠性和降低了浏览器和客户端之间的负载。这样做的一个重要原因是，很多防火墙屏蔽80以外的端口，迫使越来越多的应用迁移到HTTP上来了。</p>
<p>11年的websocket草案的变迁中，有的浏览器支持的是旧版本的websocket，比如iPhone4上的safari使用的WebSocket是旧版的握手协议,那么就要使用就的握手协议来制做服务器端。如今只有Safari支持旧版本的协议，Chrome和Firefox最新版都已升级至Hybi-10（协议地址）。因此，我们再来看一下WebSocket新版协议Hybi-10。这次协议变更非常大，主要集中在握手协议和数据传输的格式上。</p>
<h2 id="握手协议">握手协议</h2><p>我们先来看一下大致的区别：</p>
<p>最老的websocket草案标准中是没有安全key，草案7.5、7.6中有两个安全key，而现在的草案10中只有一个安全key，即将 7.5、7.6中http头中的”Sec-WebSocket-Key1″与”Sec-WebSocket-Key2″合并为了一个”Sec- WebSocket-Key”<br>把http头中Upgrade的值由”WebSocket”修改为了”websocket”；http头中的”-Origin”修改为了”Sec-WebSocket-Origin”;<br>增加了http头”Sec-WebSocket-Accept”，用来返回原来草案7.5、7.6服务器返回给客户端的握手验证，原来是以内容的形式返回，现在是放到了http头中；另外服务器返回客户端的验证方式也有变化。<br>服务器生成验证的方式变化较大，我们来做一介绍。</p>
<h3 id="旧版：">旧版：</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">GET / HTTP/<span class="number">1.1</span></span><br><span class="line">Upgrade: WebSocket</span><br><span class="line">Connection: Upgrade</span><br><span class="line">Host: <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">1337</span></span><br><span class="line">Origin: http:<span class="comment">//127.0.0.1:8000</span></span><br><span class="line">Cookie: sessionid=xxxx; calView=day; dayCurrentDate=<span class="number">1314288000000</span></span><br><span class="line">Sec-WebSocket-Key1: cV`p1* <span class="number">42</span><span class="preprocessor">#<span class="number">7</span>  ^<span class="number">9</span>&#125;_ <span class="number">647</span>  <span class="number">08</span>&#123;</span></span><br><span class="line">Sec-WebSocket-Key2: O8 <span class="number">415</span> <span class="number">8</span>x37R A8   <span class="number">4</span></span><br><span class="line">;<span class="string">"######</span></span><br></pre></td></tr></table></figure>
<p>旧版生成Token的方法如下：</p>
<p>取出Sec-WebSocket-Key1中的所有数字字符形成一个数值，这里是1427964708，然后除以Key1中的空格数目，得到一个数值，保留该数值整数位，得到数值N1；对Sec-WebSocket-Key2采取同样的算法，得到第二个整数N2；把N1和N2按照Big- Endian字符序列连接起来，然后再与另外一个Key3连接，得到一个原始序列ser_key。Key3是指在握手请求最后，有一个8字节的奇怪的字符串”;”######”，这个就是Key3。然后对ser_key进行一次md5运算得出一个16字节长的digest，这就是老版本协议需要的 token，然后将这个token附在握手消息的最后发送回Client，即可完成握手。</p>
<h3 id="新版：">新版：</h3><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="request">GET <span class="string">/</span> HTTP/1.1</span></span><br><span class="line"><span class="attribute">Upgrade</span>: <span class="string">websocket</span></span><br><span class="line"><span class="attribute">Connection</span>: <span class="string">Upgrade</span></span><br><span class="line"><span class="attribute">Host</span>: <span class="string">127.0.0.1:1337</span></span><br><span class="line"><span class="attribute">Sec-WebSocket-Origin</span>: <span class="string">http://127.0.0.1:8000</span></span><br><span class="line"><span class="attribute">Sec-WebSocket-Key</span>: <span class="string">erWJbDVAlYnHvHNulgrW8Q==</span></span><br><span class="line"><span class="attribute">Sec-WebSocket-Version</span>: <span class="string">8</span></span><br><span class="line"><span class="attribute">Cookie</span>: <span class="string">csrftoken=xxxxxx; sessionid=xxxxx</span></span><br></pre></td></tr></table></figure>
<p>新版生成Token的方法如下：</p>
<p>首先服务器将key（长度24）截取出来，如4tAjitqO9So2Wu8lkrsq3w==，用它和自定义的一个字符串（长度 36）258EAFA5-E914-47DA-95CA-C5AB0DC85B11连接起来，然后把这一字符串进行SHA-1算法加密，得到长度为20字节的二进制数据，再将这些数据经过Base64编码，最终得到服务端的密钥，也就是ser_key。服务器将ser_key附在返回值Sec- WebSocket-Accept后，至此握手成功。</p>
<p>WebSocket也有自己一套帧协议。数据报文格式如下：</p>
<figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"> 0                   1                   2                   3</span><br><span class="line"></span><br><span class="line"> 01234567890123456789012345678901</span><br><span class="line"></span><br><span class="line">+-+-+-+-+-------+-+-------------+-------------------------------+</span><br><span class="line"></span><br><span class="line">|<span class="string">F</span>|<span class="string">R</span>|<span class="string">R</span>|<span class="string">R</span>|<span class="string">opcode</span>|<span class="string">M</span>|<span class="string">Payload len</span>|<span class="string">    Extended payload length    </span>|</span><br><span class="line"></span><br><span class="line">|<span class="string">I</span>|<span class="string">S</span>|<span class="string">S</span>|<span class="string">S</span>|<span class="string">  (4)  </span>|<span class="string">A</span>|<span class="string">     (7)     </span>|<span class="string">             (16/63)           </span>|</span><br><span class="line"></span><br><span class="line">|<span class="string">N</span>|<span class="string">V</span>|<span class="string">V</span>|<span class="string">V</span>|<span class="string">       </span>|<span class="string">S</span>|<span class="string">             </span>|<span class="string">   (ifpayload len==126/127)   </span>|</span><br><span class="line"></span><br><span class="line">||<span class="string">1</span>|<span class="string">2</span>|<span class="string">3</span>|<span class="string">       </span>|<span class="string">K</span>|<span class="string">             </span>|<span class="string">                               </span>|</span><br><span class="line"></span><br><span class="line">+-+-+-+-+-------+-+-------------+---------------+</span><br><span class="line"></span><br><span class="line">|<span class="string">     Extended payload length continued,ifpayload len==127  </span>|</span><br><span class="line"></span><br><span class="line">+---------------+-------------------------------+</span><br><span class="line"></span><br><span class="line">|<span class="string">                               </span>|<span class="string">Masking-key,ifMASK set to1  </span>|</span><br><span class="line"></span><br><span class="line">+-------------------------------+-------------------------------+</span><br><span class="line"></span><br><span class="line">|<span class="string">Masking-key(continued)       </span>|<span class="string">          Payload Data         </span>|</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------+</span><br><span class="line"></span><br><span class="line">:                     Payload Data continued...                :</span><br><span class="line"></span><br><span class="line">+-------------------------------+</span><br><span class="line"></span><br><span class="line">|<span class="string">                     Payload Data continued...                </span>|</span><br><span class="line"></span><br><span class="line">+---------------------------------------------------------------+</span><br></pre></td></tr></table></figure>
<p>FIN：1位，用来表明这是一个消息的最后的消息片断，当然第一个消息片断也可能是最后的一个消息片断；</p>
<p>RSV1, RSV2, RSV3: 分别都是1位，如果双方之间没有约定自定义协议，那么这几位的值都必须为0,否则必须断掉WebSocket连接；</p>
<p>Opcode:4位操作码，定义有效负载数据，如果收到了一个未知的操作码，连接也必须断掉，以下是定义的操作码：</p>
<p>%x0 表示连续消息片断<br>%x1 表示文本消息片断<br>%x2 表未二进制消息片断<br>%x3-7 为将来的非控制消息片断保留的操作码<br>%x8 表示连接关闭<br>%x9 表示心跳检查的ping<br>%xA 表示心跳检查的pong<br>%xB-F 为将来的控制消息片断的保留操作码<br>Mask:1位，定义传输的数据是否有加掩码,如果设置为1,掩码键必须放在masking-key区域，客户端发送给服务端的所有消息，此位的值都是1；</p>
<p>Payload length: 传输数据的长度，以字节的形式表示：7位、7+16位、或者7+64位。如果这个值以字节表示是0-125这个范围，那这个值就表示传输数据的长度；如果这个值是126，则随后的两个字节表示的是一个16进制无符号数，用来表示传输数据的长度；如果这个值是127,则随后的是8个字节表示的一个64位无符合数，这个数用来表示传输数据的长度。多字节长度的数量是以网络字节的顺序表示。负载数据的长度为扩展数据及应用数据之和，扩展数据的长度可能为0,因而此时负载数据的长度就为应用数据的长度。</p>
<p>Masking-key:0或4个字节，客户端发送给服务端的数据，都是通过内嵌的一个32位值作为掩码的；掩码键只有在掩码位设置为1的时候存在。<br>Payload data:  (x+y)位，负载数据为扩展数据及应用数据长度之和。<br>Extension data:x位，如果客户端与服务端之间没有特殊约定，那么扩展数据的长度始终为0，任何的扩展都必须指定扩展数据的长度，或者长度的计算方式，以及在握手时如何确定正确的握手方式。如果存在扩展数据，则扩展数据就会包括在负载数据的长度之内。<br>Application data:y位，任意的应用数据，放在扩展数据之后，应用数据的长度=负载数据的长度-扩展数据的长度。</p>
<h1 id="MQTT">MQTT</h1><blockquote>
<p>（Message Queuing Telemetry Transport，消息队列遥测传输）是轻量级基于代理的发布/订阅的消息传输协议，设计思想是开放、简单、轻量、易于实现。这些特点使它适用于受限环境。例如，但不仅限于此：</p>
</blockquote>
<p>网络代价昂贵，带宽低、不可靠。<br>在嵌入设备中运行，处理器和内存资源有限。<br>该协议的特点有：</p>
<ul>
<li>使用发布/订阅消息模式，提供一对多的消息发布，解除应用程序耦合。</li>
<li>对负载内容屏蔽的消息传输。</li>
<li>使用 TCP/IP 提供网络连接。</li>
<li>有三种消息发布服务质量：</li>
<li>“至多一次”，消息发布完全依赖底层 TCP/IP 网络。会发生消息丢失或重复。这一级别可用于如下情况，环境传感器数据，丢失一次读记录无所谓，因为不久后还会有第二次发送。</li>
<li>“至少一次”，确保消息到达，但消息重复可能会发生。</li>
<li>“只有一次”，确保消息到达一次。这一级别可用于如下情况，在计费系统中，消息重复或丢失会导致不正确的结果。</li>
<li>小型传输，开销很小（固定长度的头部是 2 字节），协议交换最小化，以降低网络流量。</li>
<li>使用 Last Will 和 Testament 特性通知有关各方客户端异常中断的机制。</li>
</ul>
<p>早在1999年，IBM的Andy Stanford-Clark博士以及Arcom公司ArlenNipper博士发明了MQTT（Message Queuing Telemetry Transport，消息队列遥测传输）技术。BM和St. Jude医疗中心通过MQTT开发了一套Merlin系统，该系统使用了用于家庭保健的传感器。St. Jude医疗中心设计了一个叫做Merlin@home的心脏装置，这种无限发射器可以用来监控那些已经植入复律-除颤器和起搏器（两者都是基本的传感器）的心脏病人。</p>
<p>该产品利用MQTT把病人的即时更新信息传给医生/医院，然后医院进行保存。这样的话，病人就不用亲自去医院检查心脏仪器了，医生可以随时查看病人的数据，给出建议，病人在家里就可以自行检查。</p>
<p>IBM称该发射器包括一个大型触摸屏，一个嵌入式键盘平台，以及一个Linux操作系统。</p>
<p>在未来几年，MQTT的应用会越来越广，值得关注。</p>
<p>通过MQTT协议，目前已经扩展出了数十个MQTT服务器端程序，可以通过PHP，JAVA，Python，C，C#等系统语言来向MQTT发送相关消息。</p>
<p>此外，国内很多企业都广泛使用MQTT作为Android手机客户端与服务器端推送消息的协议。其中Sohu，Cmstop手机客户端中均有使用到MQTT作为消息推送消息。据Cmstop主要负责消息推送的高级研发工程师李文凯称，随着移动互联网的发展，MQTT由于开放源代码，耗电量小等特点，将会在移动消息推送领域会有更多的贡献，在物联网领域，传感器与服务器的通信，信息的收集，MQTT都可以作为考虑的方案之一。在未来MQTT会进入到我们生活的各各方面。</p>
<p>如果需要下载MQTT服务器端，可以直接去MQTT官方网站点击software进行下载MQTT协议衍生出来的各个不同版本。</p>
<p>MQTT和TCP、WebSocket的关系可以用下图一目了然:</p>
<p><img src="/files/092222479092653.png"></p>
<p>MQTT协议专注于网络、资源受限环境，建立之初不曾考虑WEB环境。HTML5 Websocket是建立在TCP基础上的双通道通信，和TCP通信方式很类似，适用于WEB浏览器环境。虽然MQTT基因层面选择了TCP作为通信通道，但我们添加个编解码方式，MQTT over Websocket也可以的。这样做的好处，MQTT的使用范畴被扩展到HTML5、桌面端浏览器、移动端WebApp、Hybrid等，多了一些想像空间。这样看来，无论是移动端，还是WEB端，MQTT都会有自己的使用空间。</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2016/01/06/Async in Spring/" itemprop="url">
                Async in Spring
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2016-01-06T09:51:27+08:00" content="2016-01-06">
            2016-01-06
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2016/01/06/Async in Spring/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2016/01/06/Async in Spring/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><h1 id="Async_in_Spring">Async in Spring</h1><h1 id="1-_Overview">1. Overview</h1><p>In this article we’ll explore the asynchronous execution support in Spring – and the @Async annotation.</p>
<p>Simply put – annotating a method of a bean with @Async will make it execute in a separate thread i.e. the caller will not wait for the completion of the called method.</p>
<h1 id="2-_Enable_Async_Support">2. Enable Async Support</h1><p>Let’s start by enabling asynchronous processing with Java configuration – by simply adding the @EnableAsync to a configuration class:</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">@Configuration</span></span><br><span class="line"><span class="variable">@EnableAsync</span></span><br><span class="line">public class SpringAsyncConfig &#123; ... &#125;</span><br></pre></td></tr></table></figure>
<p>The enable annotation is enough, but as you’d expect, there are also a few simple options for configuration as well:</p>
<ul>
<li>annotation – by default, @EnableAsync detects Spring’s @Async annotation and the EJB 3.1 javax.ejb.Asynchronous; this option can be used to detect other, user defined annotation types as well</li>
<li>mode – indicates the type of advice that should be used – JDK proxy-based or AspectJ weaving</li>
<li>proxyTargetClass – indicates the type of proxy that should be used – CGLIB or JDK; this attribute has effect only if the mode is set to AdviceMode.PROXY</li>
<li>order – sets the order in which AsyncAnnotationBeanPostProcessor should be applied; by default it runs last, just so that it can take into account all existing proxies</li>
</ul>
<p>Asynchronous processing can also be enabled using XML configuration – by using the task namespace:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">task:executor</span> <span class="attribute">id</span>=<span class="value">"myexecutor"</span> <span class="attribute">pool-size</span>=<span class="value">"5"</span>  /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">task:annotation-driven</span> <span class="attribute">executor</span>=<span class="value">"myexecutor"</span>/&gt;</span></span><br></pre></td></tr></table></figure>
<h1 id="3-_The_@Async_Annotation">3. The @Async Annotation</h1><p>First – let’s go over the rules – @Async has two limitations:</p>
<ul>
<li>it must be applied to public methods only</li>
<li>self invocation – calling the async method from within the same class – won’t work</li>
</ul>
<p>The reasons are simple – the method needs to be public so that it can be proxied. And self-invocation doesn’t work because it bypasses the proxy and calls the underlying method directly.</p>
<h3 id="3-1-_Methods_with_void_Return_Type">3.1. Methods with void Return Type</h3><p>Following is the simple way to configure a method with void return type to run asynchronously:</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="at_rule">@<span class="keyword">Async</span></span><br><span class="line">public void <span class="function">asyncMethodWithVoidReturnType</span>() </span>&#123;</span><br><span class="line">    <span class="tag">System</span><span class="class">.out</span><span class="class">.println</span>("<span class="tag">Execute</span> <span class="tag">method</span> <span class="tag">asynchronously</span>. "</span><br><span class="line">      + <span class="tag">Thread</span><span class="class">.currentThread</span>()<span class="class">.getName</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-2-_Methods_With_Return_Type">3.2. Methods With Return Type</h3><p>@Async can also be applied to a method with return type – by wrapping the actual return in a Future:</p>
<figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">@Async</span><br><span class="line"><span class="keyword">public</span> Future&lt;<span class="keyword">String</span>&gt; asyncMethodWithReturnType() &#123;</span><br><span class="line">    System.out.<span class="built_in">println</span>(<span class="string">"Execute method asynchronously - "</span></span><br><span class="line">      + Thread.currentThread().getName());</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        Thread.sleep(<span class="number">5000</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> AsyncResult&lt;<span class="keyword">String</span>&gt;(<span class="string">"hello world !!!!"</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Spring also provides a AsyncResult class which implements Future. This can be used to track the result of asynchronous method execution.</p>
<p>Now, let’s invoke the above method and retrieve the result of the asynchronous process using the Future object.</p>
<figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> testAsyncAnnotationForMethodsWithReturnType()</span><br><span class="line">    <span class="keyword">throws</span> InterruptedException, ExecutionException &#123;</span><br><span class="line">    System.out.<span class="built_in">println</span>(<span class="string">"Invoking an asynchronous method. "</span></span><br><span class="line">      + Thread.currentThread().getName());</span><br><span class="line">    Future&lt;<span class="keyword">String</span>&gt; future = asyncAnnotationExample.asyncMethodWithReturnType();</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (future.isDone()) &#123;</span><br><span class="line">            System.out.<span class="built_in">println</span>(<span class="string">"Result from asynchronous process - "</span> + future.<span class="built_in">get</span>());</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.<span class="built_in">println</span>(<span class="string">"Continue doing something else. "</span>);</span><br><span class="line">        Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="4-_The_Executor">4. The Executor</h1><p>By default Spring uses a SimpleAsyncTaskExecutor to actually run these methods asynchronously. The defaults can be overridden at two levels – at the application level or at the individual method level.</p>
<h3 id="4-1-_Override_the_Executor_at_the_Method_Level">4.1. Override the Executor at the Method Level</h3><p>The required executor needs to be declared in a configuration class:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="annotation">@Configuration</span></span><br><span class="line"><span class="annotation">@EnableAsync</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringAsyncConfig</span> </span>&#123;</span><br><span class="line">     </span><br><span class="line">    <span class="annotation">@Bean</span>(name = <span class="string">"threadPoolTaskExecutor"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Executor <span class="title">threadPoolTaskExecutor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ThreadPoolTaskExecutor();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Then the executor name should be provided as an attribute in @Async:</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="at_rule">@<span class="keyword">Async("threadPoolTaskExecutor")</span></span><br><span class="line">public void <span class="function">asyncMethodWithConfiguredExecutor</span>() </span>&#123;</span><br><span class="line">    <span class="tag">System</span><span class="class">.out</span><span class="class">.println</span>("<span class="tag">Execute</span> <span class="tag">method</span> <span class="tag">with</span> <span class="tag">configured</span> <span class="tag">executor</span> <span class="tag">-</span> "</span><br><span class="line">      + <span class="tag">Thread</span><span class="class">.currentThread</span>()<span class="class">.getName</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="4-2-_Override_the_Executor_at_the_Application_Level">4.2. Override the Executor at the Application Level</h3><p>The configuration class should implement the AsyncConfigurer interface – which will mean that it has the implement the getAsyncExecutor() method. It’s here that we will return the executor for the entire application – this now becomes the default executor to run methods annotated with @Async:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="annotation">@Configuration</span></span><br><span class="line"><span class="annotation">@EnableAsync</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpringAsyncConfig</span> <span class="keyword">implements</span> <span class="title">AsyncConfigurer</span> </span>&#123;</span><br><span class="line">     </span><br><span class="line">    <span class="annotation">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Executor <span class="title">getAsyncExecutor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ThreadPoolTaskExecutor();</span><br><span class="line">    &#125;</span><br><span class="line">     </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="5-_Exception_Handling">5. Exception Handling</h1><p>When a method return type is a Future, exception handling is easy – Future.get() method will throw the exception.</p>
<p>But, if the return type is void, exceptions will not be propagated to the calling thread. Hence we need to add extra configurations to handle exceptions.</p>
<p>We’ll create a custom async exception handler by implementing AsyncUncaughtExceptionHandler interface. The handleUncaughtException() method is invoked when there are any uncaught asynchronous exceptions:</p>
<figure class="highlight nimrod"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public class <span class="type">CustomAsyncExceptionHandler</span>  implements <span class="type">AsyncUncaughtExceptionHandler</span> &#123;</span><br><span class="line"> </span><br><span class="line">    @<span class="type">Override</span></span><br><span class="line">    public <span class="type">void</span> handleUncaughtException(<span class="type">Throwable</span> throwable, <span class="type">Method</span> <span class="keyword">method</span>, <span class="type">Object</span>... obj) &#123;</span><br><span class="line">        <span class="type">System</span>.<span class="keyword">out</span>.println(<span class="string">"Exception message - "</span> + throwable.getMessage());</span><br><span class="line">        <span class="type">System</span>.<span class="keyword">out</span>.println(<span class="string">"Method name - "</span> + <span class="keyword">method</span>.getName());</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">Object</span> param : obj) &#123;</span><br><span class="line">            <span class="type">System</span>.<span class="keyword">out</span>.println(<span class="string">"Parameter value - "</span> + param);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">     </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>In the previous section we looked at the AsyncConfigurer interface implemented by the configuration class. As part of that, we also need to override the getAsyncUncaughtExceptionHandler() method to return our custom asynchronous exception handler:</p>
<figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="annotation">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="function">AsyncUncaughtExceptionHandler <span class="title">getAsyncUncaughtExceptionHandler</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> CustomAsyncExceptionHandler();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="6-_Conclusion">6. Conclusion</h1><p>In this tutorial we looked at running asynchronous code with Spring. We started with the very basic configuration and annotation to make it work but also looked at more advanced configs such as providing our own executor, or exception handling strategies.</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2015/11/20/Kafka架构和原理深度剖析/" itemprop="url">
                Kafka架构和原理深度剖析
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2015-11-20T13:56:30+08:00" content="2015-11-20">
            2015-11-20
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2015/11/20/Kafka架构和原理深度剖析/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2015/11/20/Kafka架构和原理深度剖析/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><h1 id="背景介绍">背景介绍</h1><h2 id="Kafka简介">Kafka简介</h2><pre><code>Kafka是一种分布式的，基于发布/订阅的消息系统。主要设计目标如下：

<span class="keyword">*</span>以时间复杂度为O(1)的方式提供消息持久化能力，并保证即使对TB级以上数据也能保证常数时间的访问性能
<span class="keyword">*</span>高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输
<span class="keyword">*</span>支持Kafka Server间的消息分区，及分布式消息消费，同时保证每个partition内的消息顺序传输
<span class="keyword">*</span>同时支持离线数据处理和实时数据处理
</code></pre><h2 id="为什么要用Message_Queue">为什么要用Message Queue</h2><h4 id="解耦">解耦</h4><pre><code>在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息队列在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束
</code></pre><h4 id="冗余">冗余</h4><pre><code>有时在处理数据的时候处理过程会失败。除非数据被持久化，否则将永远丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失 风险。在被许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理过程明确的指出该消息已经被处理完毕，确保你的 数据被安全的保存直到你使用完毕。
</code></pre><h4 id="扩展性">扩展性</h4><pre><code>因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的；只要另外增加处理过程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。
</code></pre><h4 id="灵活性_&amp;_峰值处理能力">灵活性 &amp; 峰值处理能力</h4><pre><code>在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住增长的访问压力，而不是因为超出负荷的请求而完全崩溃。
</code></pre><h4 id="可恢复性">可恢复性</h4><pre><code>当体系的一部分组件失效，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。而这种允许重试或者延后处理请求的能力通常是造就一个略感不便的用户和一个沮丧透顶的用户之间的区别。
</code></pre><h4 id="送达保证">送达保证</h4><pre><code>消息队列提供的冗余机制保证了消息能被实际的处理，只要一个进程读取了该队列即可。在此基础上，IronMQ提供了一个”只送达一次”保证。无论有多少进 程在从队列中领取数据，每一个消息只能被处理一次。这之所以成为可能，是因为获取一个消息只是”预定”了这个消息，暂时把它移出了队列。除非客户端明确的 表示已经处理完了这个消息，否则这个消息会被放回队列中去，在一段可配置的时间之后可再次被处理。
</code></pre><h4 id="顺序保证">顺序保证</h4><pre><code>在许多情况下，数据处理的顺序都很重要。消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。IronMO保证消息浆糊通过FIFO（先进先出）的顺序来处理，因此消息在队列中的位置就是从队列中检索他们的位置。
</code></pre><h4 id="缓冲">缓冲</h4><pre><code>在任何重要的系统中，都会有需要不同的处理时间的元素。例如,加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行—写入队列的处理会尽可能的快速，而不受从队列读的预备处理的约束。该缓冲有助于控制和优化数据流经过系统的速度。
</code></pre><h4 id="理解数据流">理解数据流</h4><pre><code>在一个分布式系统里，要得到一个关于用户操作会用多长时间及其原因的总体印象，是个巨大的挑战。消息系列通过消息被处理的频率，来方便的辅助确定那些表现不佳的处理过程或领域，这些地方的数据流都不够优化。
</code></pre><h4 id="异步通信">异步通信</h4><pre><code>很多时候，你不想也不需要立即处理消息。消息队列提供了异步处理机制，允许你把一个消息放入队列，但并不立即处理它。你想向队列中放入多少消息就放多少，然后在你乐意的时候再去处理它们。
</code></pre><h2 id="常用Message_Queue对比">常用Message Queue对比</h2><h3 id="RabbitMQ">RabbitMQ</h3><pre><code><span class="label">RabbitMQ</span>是使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP, STOMP，也正因如此，它非常重量级，更适合于企业级的开发。同时实现了<span class="keyword">Broker构架，这意味着消息在发送给客户端时先在中心队列排队。对路由，负 </span>载均衡或者数据持久化都有很好的支持。
</code></pre><h3 id="Redis">Redis</h3><pre><code>Redis是一个基于Key-Value对的NoSQL数据库，开发维护很活跃。虽然它是一个Key-Value数据库存储系统，但它本身支持MQ功能， 所以完全可以当做一个轻量级的队列服务来使用。对于RabbitMQ和Redis的入队和出队操作，各执行<span class="number">100</span>万次，每<span class="number">10</span>万次记录一次执行时间。测试 数据分为<span class="number">128</span>Bytes、<span class="number">512</span>Bytes、<span class="number">1</span>K和<span class="number">10</span>K四个不同大小的数据。实验表明：入队时，当数据比较小时Redis的性能要高于 RabbitMQ，而如果数据大小超过了<span class="number">10</span>K，Redis则慢的无法忍受；出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ 的出队性能则远低于Redis。
</code></pre><h3 id="ZeroMQ">ZeroMQ</h3><pre><code>ZeroMQ号称最快的消息队列系统，尤其针对大吞吐量的需求场景。ZMQ能够实现RabbitMQ不擅长的高级/复杂的队列，但是开发人员需要自己组合 多种技术框架，技术上的复杂度是对这MQ能够应用成功的挑战。ZeroMQ具有一个独特的非中间件的模式，你不需要安装和运行一个消息服务器或中间件，因 为你的应用程序将扮演了这个服务角色。你只需要简单的引用ZeroMQ程序库，可以使用NuGet安装，然后你就可以愉快的在应用程序之间发送消息了。但 是ZeroMQ仅提供非持久性的队列，也就是说如果<span class="preprocessor">down</span>机，数据将会丢失。其中，Twitter的Storm中默认使用ZeroMQ作为数据流的传 输。
</code></pre><h3 id="ActiveMQ">ActiveMQ</h3><pre><code>ActiveMQ是Apache下的一个子项目。 类似于ZeroMQ，它能够以代理人和点对点的技术实现队列。同时类似于RabbitMQ，它少量代码就可以高效地实现高级应用场景。
</code></pre><h3 id="Kafka/Jafka">Kafka/Jafka</h3><pre><code>Kafka是Apache下的一个子项目，是一个高性能跨语言分布式Publish/Subscribe消息队列系统，而Jafka是在Kafka之上孵 化而来的，即Kafka的一个升级版。具有以下特性：快速持久化，可以在<span class="function"><span class="title">O</span><span class="params">(<span class="number">1</span>)</span></span>的系统开销下进行消息持久化；高吞吐，在一台普通的服务器上既可以达到 <span class="number">10</span>W/s的吞吐速率；完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现复杂均衡；支持Hadoop 数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka通过Hadoop的并行 加载机制来统一了在线和离线的消息处理，这一点也是本课题所研究系统所看重的。Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。
</code></pre><h2 id="Kafka解析">Kafka解析</h2><h3 id="Terminology">Terminology</h3><h4 id="Broker">Broker</h4><pre><code>Kafka集群包含一个或多个服务器，这种服务器被称为broker
</code></pre><h4 id="Topic">Topic</h4><pre><code>每条发布到Kafka集群的消息都有一个类别，这个类别被称为topic。（物理上不同topic的消息分开存储，逻辑上一个topic的消息虽然保存于一个或多个broker上但用户只需指定消息的topic即可生产或消费数据而不必关心数据存于何处）
</code></pre><h4 id="Partition">Partition</h4><pre><code>parition是物理上的概念，每个topic包含一个或多个<span class="keyword">partition</span>，创建topic时可指定parition数量。每个<span class="keyword">partition</span>对应于一个文件夹，该文件夹下存储该<span class="keyword">partition</span>的数据和索引文件
</code></pre><h4 id="Producer">Producer</h4><pre><code>负责发布消息到Kafka broker
</code></pre><h4 id="Consumer">Consumer</h4><pre><code>消费消息。每个consumer属于一个特定的consuer <span class="keyword">group</span>（可为每个consumer指定<span class="keyword">group</span> name，若不指定<span class="keyword">group</span> name则属于默认的<span class="keyword">group</span>）。使用consumer high level API时，同一topic的一条消息只能被同一个consumer <span class="keyword">group</span>内的一个consumer消费，但多个consumer <span class="keyword">group</span>可同时消费这一消息。
</code></pre><h2 id="Kafka架构">Kafka架构</h2><pre><code>&lt;img src=<span class="string">"/files/0924-1.jpg"</span>&gt;
如上图所示，一个典型的kafka集群中包含若干producer（可以是web前端产生的page view，或者是服务器日志，系统CPU、memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高）， 若干consumer <span class="keyword">group</span>，以及一个Zookeeper集 群。Kafka通过Zookeeper管理集群配置，选举leader，以及在consumer <span class="keyword">group</span>发生变化时进行rebalance。producer使用<span class="keyword">push</span>模式将消息发布到broker，consumer使用pull模式从 broker订阅并消费消息。
</code></pre><h3 id="Push_vs-_Pull">Push vs. Pull</h3><pre><code>作为一个messaging <span class="keyword">system</span>，Kafka遵循了传统的方式，选择由producer向broker <span class="keyword">push</span>消息并由consumer从broker pull消息。一些logging-centric <span class="keyword">system</span>，比如Facebook的Scribe和Cloudera的Flume,采用非常不同的<span class="keyword">push</span>模式。事实上，<span class="keyword">push</span>模式和pull模式各有优劣。
<span class="keyword">push</span>模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。<span class="keyword">push</span>模式的目标是尽可能以最快速度传递消息，但是这样很容易造 成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据consumer的消费能力以适当的速率消费消息。
</code></pre><h3 id="Topic_&amp;_Partition">Topic &amp; Partition</h3><pre><code>Topic在逻辑上可以被认为是一个在的queue，每条消费都必须指定它的topic，可以简单理解为必须指明把这条消息放进哪个queue里。 为了使得Kafka的吞吐率可以水平扩展，物理上把topic分成一个或多个partition，每个partition在物理上对应一个文件夹，该文件 夹下存储这个partition的所有消息和索引文件。

&lt;img src=<span class="string">"/files/0924-2.jpg"</span>&gt;

每个日志文件都是“<span class="built_in">log</span> entries”序列，每一个<span class="built_in">log</span> entry包含一个<span class="number">4</span>字节整型数（值为N），其后跟N个字节的消息体。每条消息都有一个当前partition下唯一的<span class="number">64</span>字节的<span class="built_in">offset</span>，它指明了这条消息的起始位置。磁盘上存储的消费格式如下：
message <span class="built_in">length</span> ： <span class="number">4</span> <span class="keyword">bytes</span> (<span class="built_in">value</span>: <span class="number">1</span>+<span class="number">4</span>+n)
“magic” <span class="built_in">value</span> ： <span class="number">1</span> <span class="keyword">byte</span>
crc ： <span class="number">4</span> <span class="keyword">bytes</span>
payload ： n <span class="keyword">bytes</span>
这个“<span class="built_in">log</span> entries”并非由一个文件构成，而是分成多个<span class="keyword">segment</span>，每个<span class="keyword">segment</span>名为该<span class="keyword">segment</span>第一条消息的<span class="built_in">offset</span>和“.kafka”组成。另外会有一个索引文件，它标明了每个<span class="keyword">segment</span>下包含的<span class="built_in">log</span> entry的<span class="built_in">offset</span>范围，如下图所示。

&lt;img src=<span class="string">"/files/0924-3.jpg"</span>&gt;

因为每条消息都被append到该partition中，是顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。

&lt;img src=<span class="string">"/files/0924-4.jpg"</span>&gt;

每一条消息被发送到broker时，会根据paritition规则选择被存储到哪一个partition。如果partition规则设置的合理，所有 消息可以均匀分布到不同的partition里，这样就实现了水平扩展。（如果一个topic对应一个文件，那这个文件所在的机器I/O将会成为这个 topic的性能瓶颈，而partition解决了这个问题）。在创建topic时可以在$KAFKA_HOME/config/server.properties中指定这个partition的数量(如下所示)，当然也可以在topic创建之后去修改parition数量。
</code></pre><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The default number of log partitions per topic. More partitions allow greater</span></span><br><span class="line"><span class="comment"># parallelism for consumption, but this will also result in more files across</span></span><br><span class="line"><span class="comment"># the brokers.</span></span><br><span class="line"><span class="built_in">num</span>.partitions=<span class="number">3</span></span><br></pre></td></tr></table></figure>
<pre><code>在发送一条消息时，可以指定这条消息的<span class="keyword">key</span>，producer根据这个<span class="keyword">key</span>和partition机制来判断将这条消息发送到哪个parition。 paritition机制可以通过指定producer的paritition. <span class="keyword">class</span>这一参数来指定，该<span class="keyword">class</span>必须实现kafka.producer.Partitioner接口。本例中如果<span class="keyword">key</span>可以被解析为整数则将对应的整数与partition总数取余，该消息会被发送到该数对应的partition。（每个parition都会有个序号）
</code></pre><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> kafka.producer.Partitioner;</span><br><span class="line"><span class="keyword">import</span> kafka.utils.VerifiableProperties;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> class JasonPartitioner implements Partitioner &#123;</span><br><span class="line">    <span class="keyword">public</span> JasonPartitioner(VerifiableProperties verifiableProperties) &#123;&#125;</span><br><span class="line">    @Override</span><br><span class="line">    <span class="keyword">public</span> <span class="built_in">int</span> partition(<span class="keyword">Object</span> <span class="variable">key</span>, <span class="built_in">int</span> numPartitions) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="built_in">int</span> partitionNum = Integer.parseInt((<span class="keyword">String</span>) <span class="variable">key</span>);</span><br><span class="line">            <span class="keyword">return</span> Math.<span class="built_in">abs</span>(Integer.parseInt((<span class="keyword">String</span>) <span class="variable">key</span>) % numPartitions);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="keyword">return</span> Math.<span class="built_in">abs</span>(<span class="variable">key</span>.hashCode() % numPartitions);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<pre><code>如果将上例中的<span class="keyword">class</span>作为partition.<span class="keyword">class</span>，并通过如下代码发送<span class="number">20</span>条消息（key分别为<span class="number">0</span>，<span class="number">1</span>，<span class="number">2</span>，<span class="number">3</span>）至topic2（包含<span class="number">4</span>个partition）。
</code></pre><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> sendMessage() <span class="keyword">throws</span> InterruptedException&#123;</span><br><span class="line">　　<span class="keyword">for</span>(<span class="built_in">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">5</span>; i++)&#123;</span><br><span class="line">　　      List messageList = <span class="keyword">new</span> ArrayList&lt;KeyedMessage&lt;<span class="keyword">String</span>, <span class="keyword">String</span>&gt;&gt;();</span><br><span class="line">　　      <span class="keyword">for</span>(<span class="built_in">int</span> j = <span class="number">0</span>; j &lt; <span class="number">4</span>; j++）&#123;</span><br><span class="line">　　          messageList.<span class="built_in">add</span>(<span class="keyword">new</span> KeyedMessage&lt;<span class="keyword">String</span>, <span class="keyword">String</span>&gt;(<span class="string">"topic2"</span>, j+<span class="string">""</span>, <span class="string">"The "</span> + i + <span class="string">" message for key "</span> + j));</span><br><span class="line">　　      &#125;</span><br><span class="line">　　      producer.send(messageList);</span><br><span class="line">    &#125;</span><br><span class="line">　　producer.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<pre><code>则key相同的消息会被发送并存储到同一个<span class="keyword">partition</span>里，而且key的序号正好和<span class="keyword">partition</span>序号相同。（<span class="keyword">partition</span>序号从<span class="number">0</span>开始，本例中的key也正好从<span class="number">0</span>开始）。如下图所示。

&lt;img src=<span class="string">"/files/0924-5.jpg"</span>&gt;

对于传统的message queue而言，一般会删除已经被消费的消息，而Kafka集群会保留所有的消息，无论其被消费与否。当然，因为磁盘限制，不可能永久保留所有数据（实际 上也没必要），因此Kafka提供两种策略去删除旧数据。一是基于时间，二是基于<span class="keyword">partition</span>文件大小。例如可以通过配置<span class="variable">$KAFKA_HOME</span>/config/server.properties，让Kafka删除一周前的数据，也可通过配置让Kafka在<span class="keyword">partition</span>文件超过<span class="number">1</span>GB时删除旧数据，如下所示。
</code></pre><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">　　<span class="comment">######</span><span class="comment">######</span><span class="comment">######</span><span class="comment">######</span><span class="comment">##### Log Retention Policy ###</span><span class="comment">######</span><span class="comment">######</span><span class="comment">######</span><span class="comment">######</span><span class="comment">##</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># The following configurations control the disposal of log segments. The policy can</span></span><br><span class="line"><span class="comment"># be set to delete segments after a period of time, or after a given size has accumulated.</span></span><br><span class="line"><span class="comment"># A segment will be deleted whenever *either* of these criteria are met. Deletion always happens</span></span><br><span class="line"><span class="comment"># from the end of the log.</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># The minimum age of a log file to be eligible for deletion</span></span><br><span class="line">log.retention.hours=<span class="number">168</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># A size-based retention policy for logs. Segments are pruned from the log as long as the remaining</span></span><br><span class="line"><span class="comment"># segments don't drop below log.retention.bytes.</span></span><br><span class="line"><span class="comment">#log.retention.bytes=1073741824</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># The maximum size of a log segment file. When this size is reached a new log segment will be created.</span></span><br><span class="line">log.segment.bytes=<span class="number">1073741824</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># The interval at which log segments are checked to see if they can be deleted according</span></span><br><span class="line"><span class="comment"># to the retention policies</span></span><br><span class="line">log.retention.check.interval.ms=<span class="number">300000</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># By default the log cleaner is disabled and the log retention policy will default to </span></span><br><span class="line"><span class="comment">#just delete segments after their retention expires.</span></span><br><span class="line"><span class="comment"># If log.cleaner.enable=true is set the cleaner will be enabled and individual logs </span></span><br><span class="line"><span class="comment">#can then be marked for log compaction.</span></span><br><span class="line">log.cleaner.enable=<span class="literal">false</span></span><br></pre></td></tr></table></figure>
<pre><code>这里要注意，因为Kafka读取特定消息的时间复杂度为O<span class="params">(<span class="number">1</span>)</span>，即与文件大小无关，所以这里删除文件与Kafka性能无关，选择怎样的删除策略只 与磁盘以及具体的需求有关。另外，Kafka会为每一个consumer group保留一些metadata信息—当前消费的消息的position，也即<span class="built_in">offset</span>。这个<span class="built_in">offset</span>由consumer控制。正常情况下 consumer会在消费完一条消息后线性增加这个<span class="built_in">offset</span>。当然，consumer也可将<span class="built_in">offset</span>设成一个较小的值，重新消费一些消息。因为 offet由consumer控制，所以Kafka broker是无状态的，它不需要标记哪些消息被哪些consumer过，不需要通过broker去保证同一个consumer group只有一个consumer能消费某一条消息，因此也就不需要锁机制，这也为Kafka的高吞吐率提供了有力保障。
</code></pre><h3 id="Replication_&amp;_Leader_election">Replication &amp; Leader election</h3><pre><code>Kafka从<span class="number">0</span>.<span class="number">8</span>开始提供partition级别的replication，replication的数量可在<span class="variable">$KAFKA</span>_HOME/config/server.properties中配置。
</code></pre><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">default<span class="class">.replication</span><span class="class">.factor</span> = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<pre><code>该 Replication与leader election配合提供了自动的failover机制。replication对Kafka的吞吐率是有一定影响的，但极大的增强了可用性。默认情况 下，Kafka的replication数量为<span class="number">1</span>。　　每个<span class="keyword">partition</span>都有一个唯一的leader，所有的读写操作都在leader上完 成，leader批量从leader上pull数据。一般情况下<span class="keyword">partition</span>的数量大于等于broker的数量，并且所有<span class="keyword">partition</span>的 leader均匀分布在broker上。follower上的日志和其leader上的完全一样。

和大部分分布式系统一样，Kakfa处理失败需要明确定义一个broker是否alive。对于Kafka而言，Kafka存活包含两个条件，一是它必须 维护与Zookeeper的session(这个通过Zookeeper的heartbeat机制来实现)。二是follower必须能够及时将 leader的writing复制过来，不能“落后太多”。

leader会<span class="keyword">track</span>“<span class="keyword">in</span> sync”的node list。如果一个follower宕机，或者落后太多，leader将把它从”<span class="keyword">in</span> sync” list中移除。这里所描述的“落后太多”指follower复制的消息落后于leader后的条数超过预定值，该值可在<span class="variable">$KAFKA_HOME</span>/config/server.properties中配置
</code></pre><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#If a replica falls more than this many messages behind the leader, the leader will remove the follower from ISR and treat it as dead</span></span><br><span class="line">replica.lag.<span class="built_in">max</span>.messages=<span class="number">4000</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#If a follower hasn't sent any fetch requests for this window of time, the leader will remove the follower from ISR (in-sync replicas) and treat it as dead</span></span><br><span class="line">replica.lag.<span class="built_in">time</span>.<span class="built_in">max</span>.ms=<span class="number">10000</span></span><br></pre></td></tr></table></figure>
<pre><code>需要说明的是，Kafka只解决”fail/recover”，不处理“Byzantine”（“拜占庭”）问题。

一条消息只有被“in sync” list里的所有follower都从leader复制过去才会被认为已提交。这样就避免了部分数据被写进了leader，还没来得及被任何 follower复制就宕机了，而造成数据丢失（consumer无法消费这些数据）。而对于producer而言，它可以选择是否等待消息 <span class="operator"><span class="keyword">commit</span>，这可以通过request.<span class="keyword">required</span>.acks来设置。这种机制确保了只要“<span class="keyword">in</span> <span class="keyword">sync</span>” <span class="keyword">list</span>有一个或以上的flollower，一条被<span class="keyword">commit</span>的消息就不会丢失。

这里的复制机制即不是同步复制，也不是单纯的异步复制。事实上，同步复制要求“活着的”follower都复制完，这条消息才会被认为<span class="keyword">commit</span>，这种 复制方式极大的影响了吞吐率（高吞吐率是Kafka非常重要的一个特性）。而异步复制方式下，follower异步的从leader复制数据，数据只要被 leader写入<span class="keyword">log</span>就被认为已经<span class="keyword">commit</span>，这种情况下如果follwer都落后于leader，而leader突然宕机，则会丢失数据。而 Kafka的这种使用“<span class="keyword">in</span> <span class="keyword">sync</span>” <span class="keyword">list</span>的方式则很好的均衡了确保数据不丢失以及吞吐率。follower可以批量的从leader复制数据，这样极大的提高复制性能（批量写磁盘），极 大减少了follower与leader的差距（前文有说到，只要follower落后leader不太远，则被认为在“<span class="keyword">in</span> <span class="keyword">sync</span>” <span class="keyword">list</span>里）。

上文说明了Kafka是如何做<span class="keyword">replication</span>的，另外一个很重要的问题是当leader宕机了，怎样在follower中选举出新的 leader。因为follower可能落后许多或者crash了，所以必须确保选择“最新”的follower作为新的leader。一个基本的原则就 是，如果leader不在了，新的leader必须拥有原来的leader <span class="keyword">commit</span>的所有消息。这就需要作一个折衷，如果leader在标明一条消息被<span class="keyword">commit</span>前等待更多的follower确认，那在它die之后就有更 多的follower可以作为新的leader，但这也会造成吞吐率的下降。

一种非常常用的选举leader的方式是“majority 灵秀”（“少数服从多数”），但Kafka并未采用这种方式。这种模式下，如果我们有<span class="number">2</span><span class="keyword">f</span>+<span class="number">1</span>个replica（包含leader和follower）， 那在<span class="keyword">commit</span>之前必须保证有<span class="keyword">f</span>+<span class="number">1</span>个replica复制完消息，为了保证正确选出新的leader，fail的replica不能超过<span class="keyword">f</span>个。因为在剩 下的任意<span class="keyword">f</span>+<span class="number">1</span>个replica里，至少有一个replica包含有最新的所有消息。这种方式有个很大的优势，系统的latency只取决于最快的几台 <span class="keyword">server</span>，也就是说，如果<span class="keyword">replication</span> factor是<span class="number">3</span>，那latency就取决于最快的那个follower而非最慢那个。majority vote也有一些劣势，为了保证leader election的正常进行，它所能容忍的fail的follower个数比较少。如果要容忍<span class="number">1</span>个follower挂掉，必须要有<span class="number">3</span>个以上的 replica，如果要容忍<span class="number">2</span>个follower挂掉，必须要有<span class="number">5</span>个以上的replica。也就是说，在生产环境下为了保证较高的容错程度，必须要有大量 的replica，而大量的replica又会在大数据量下导致性能的急剧下降。这就是这种算法更多用在Zookeeper这种共享集群配置的系统中而很少在需要存储大量数据的系统中使用的原因。例如HDFS的HA feature是基于majority-vote-based journal，但是它的数据存储并没有使用这种expensive的方式。

实际上，leader election算法非常多，比如Zookeper的Zab, Raft和Viewstamped <span class="keyword">Replication</span>。而Kafka所使用的leader election算法更像微软的PacificA算法。

Kafka在Zookeeper中动态维护了一个ISR（<span class="keyword">in</span>-<span class="keyword">sync</span> replicas） <span class="keyword">set</span>，这个<span class="keyword">set</span>里的所有replica都跟上了leader，只有ISR里的成员才有被选为leader的可能。在这种模式下，对于<span class="keyword">f</span>+<span class="number">1</span>个 replica，一个Kafka topic能在保证不丢失已经ommit的消息的前提下容忍<span class="keyword">f</span>个replica的失败。在大多数使用场景中，这种模式是非常有利的。事实上，为了容忍<span class="keyword">f</span>个 replica的失败，majority vote和ISR在<span class="keyword">commit</span>前需要等待的replica数量是一样的，但是ISR需要的总的replica的个数几乎是majority vote的一半。

虽然majority vote与ISR相比有不需等待最慢的<span class="keyword">server</span>这一优势，但是Kafka作者认为Kafka可以通过producer选择是否被<span class="keyword">commit</span>阻塞来改善这一问题，并且节省下来的replica和磁盘使得ISR模式仍然值得。

上文提到，在ISR中至少有一个follower时，Kafka可以确保已经<span class="keyword">commit</span>的数据不丢失，但如果某一个<span class="keyword">partition</span>的所有replica都挂了，就无法保证数据不丢失了。这种情况下有两种可行的方案：

* 等待ISR中的任一个replica“活”过来，并且选它作为leader
* 选择第一个“活”过来的replica（不一定是ISR中的）作为leader

这就需要在可用性和一致性当中作出一个简单的平衡。如果一定要等待ISR中的replica“活”过来，那不可用的时间就可能会相对较长。而且如果 ISR中的所有replica都无法“活”过来了，或者数据都丢失了，这个<span class="keyword">partition</span>将永远不可用。选择第一个“活”过来的replica作为 leader，而这个replica不是ISR中的replica，那即使它并不保证已经包含了所有已<span class="keyword">commit</span>的消息，它也会成为leader而作为 consumer的数据源（前文有说明，所有读写都由leader完成）。Kafka0<span class="number">.8</span>.*使用了第二种方式。根据Kafka的文档，在以后的版本 中，Kafka支持用户通过配置选择这两种方式中的一种，从而根据不同的使用场景选择高可用性还是强一致性。

上文说明了一个parition的<span class="keyword">replication</span>过程，然尔Kafka集群需要管理成百上千个<span class="keyword">partition</span>，Kafka通过 <span class="keyword">round</span>-robin的方式来平衡<span class="keyword">partition</span>从而避免大量<span class="keyword">partition</span>集中在了少数几个节点上。同时Kafka也需要平衡leader的 分布，尽可能的让所有<span class="keyword">partition</span>的leader均匀分布在不同broker上。另一方面，优化leadership election的过程也是很重要的，毕竟这段时间相应的<span class="keyword">partition</span>处于不可用状态。一种简单的实现是暂停宕机的broker上的所有 <span class="keyword">partition</span>，并为之选举leader。实际上，Kafka选举一个broker作为controller，这个controller通过 watch Zookeeper检测所有的broker <span class="keyword">failure</span>，并负责为所有受影响的parition选举leader，再将相应的leader调整命令发送至受影响的broker，过程如下图所示。

&lt;img src=<span class="string">"/files/0924-6.jpg"</span>&gt;

这样做的好处是，可以批量的通知leadership的变化，从而使得选举过程成本更低，尤其对大量的<span class="keyword">partition</span>而言。如果controller 失败了，幸存的所有broker都会尝试在Zookeeper中创建/controller-&gt;{this broker <span class="keyword">id</span>}，如果创建成功（只可能有一个创建成功），则该broker会成为controller，若创建不成功，则该broker会等待新 controller的命令。

&lt;img src=<span class="string">"/files/0924-7.jpg"</span>&gt;</span>
</code></pre><h3 id="Consumer_group">Consumer group</h3><pre><code>（本节所有描述都是基于consumer hight level API而非low level API）。

每一个consumer实例都属于一个consumer group，每一条消息只会被同一个consumer group里的一个consumer实例消费。（不同consumer group可以同时消费同一条消息）

&lt;img src=<span class="string">"/files/0924-8.jpg"</span>&gt;

很多传统的message <span class="built_in">queue</span>都会在消息被消费完后将消息删除，一方面避免重复消费，另一方面可以保证<span class="built_in">queue</span>的长度比较少，提高效率。而如上文所将，Kafka并不删除 已消费的消息，为了实现传统message <span class="built_in">queue</span>消息只被消费一次的语义，Kafka保证保证同一个consumer group里只有一个consumer会消费一条消息。与传统message <span class="built_in">queue</span>不同的是，Kafka还允许不同consumer group同时消费同一条消息，这一特性可以为消息的多元化处理提供了支持。实际上，Kafka的设计理念之一就是同时提供离线处理和实时处理。根据这一 特性，可以使用Storm这种实时流处理系统对消息进行实时在线处理，同时使用Hadoop这种批处理系统进行离线处理，还可以同时将数据实时备份到另一 个数据中心，只需要保证这三个操作所使用的consumer在不同的consumer group即可。下图展示了Kafka在Linkedin的一种简化部署。

&lt;img src=<span class="string">"/files/0924-9.jpg"</span>&gt;

为了更清晰展示Kafka consumer group的特性，笔者作了一项测试。创建一个topic (名为topic1)，创建一个属于group1的consumer实例，并创建三个属于group2的consumer实例，然后通过producer 向topic1发送key分别为<span class="number">1</span>，<span class="number">2</span>，<span class="number">3</span>r的消息。结果发现属于group1的consumer收到了所有的这三条消息，同时group2中的<span class="number">3</span>个 consumer分别收到了key为<span class="number">1</span>，<span class="number">2</span>，<span class="number">3</span>的消息。如下图所示。

&lt;img src=<span class="string">"/files/0924-10.jpg"</span>&gt;
</code></pre><h3 id="Consumer_Rebalance">Consumer Rebalance</h3><pre><code>（本节所讲述内容均基于Kafka consumer high level API）   

Kafka保证同一consumer group中只有一个consumer会消息某条消息，实际上，Kafka保证的是稳定状态下每一个consumer实例只会消费某一个或多个特定 partition的数据，而某个partition的数据只会被某一个特定的consumer实例所消费。这样设计的劣势是无法让同一个 consumer group里的consumer均匀消费数据，优势是每个consumer不用都跟大量的broker通信，减少通信开销，同时也降低了分配难度，实现也 更简单。另外，因为同一个partition里的数据是有序的，这种设计可以保证每个partition里的数据也是有序被消费。

如果某consumer group中consumer数量少于partition数量，则至少有一个consumer会消费多个partition的数据，如果consumer 的数量与partition数量相同，则正好一个consumer消费一个partition的数据，而如果consumer的数量多于 partition的数量时，会有部分consumer无法消费该topic下任何一条消息。

如下例所示，如果topic1有<span class="operator">0，<span class="number">1</span>，<span class="number">2</span>共三个<span class="keyword">partition</span>，当group1只有一个consumer(名为consumer1)时，该 consumer可消费这<span class="number">3</span>个<span class="keyword">partition</span>的所有数据。

&lt;img src=<span class="string">"/files/0924-11.jpg"</span>&gt;

增加一个consumer(consumer2)后，其中一个consumer（consumer1）可消费<span class="number">2</span>个<span class="keyword">partition</span>的数据，另外一个consumer(consumer2)可消费另外一个<span class="keyword">partition</span>的数据。

&lt;img src=<span class="string">"/files/0924-12.jpg"</span>&gt;

再增加一个consumer(consumer3)后，每个consumer可消费一个<span class="keyword">partition</span>的数据。consumer1消费partition0，consumer2消费partition1，consumer3消费partition2

&lt;img src=<span class="string">"/files/0924-13.jpg"</span>&gt;

再增加一个consumer（consumer4）后，其中<span class="number">3</span>个consumer可分别消费一个<span class="keyword">partition</span>的数据，另外一个consumer（consumer4）不能消费topic1任何数据。

&lt;img src=<span class="string">"/files/0924-14.jpg"</span>&gt;

此时关闭consumer1，剩下的consumer可分别消费一个<span class="keyword">partition</span>的数据。

&lt;img src=<span class="string">"/files/0924-15.jpg"</span>&gt;

接着关闭consumer2，剩下的consumer3可消费<span class="number">2</span>个<span class="keyword">partition</span>，consumer4可消费<span class="number">1</span>个<span class="keyword">partition</span>。

&lt;img src=<span class="string">"/files/0924-16.jpg"</span>&gt;

再关闭consumer3，剩下的consumer4可同时消费topic1的<span class="number">3</span>个<span class="keyword">partition</span>。

&lt;img src=<span class="string">"/files/0924-17.jpg"</span>&gt;

consumer rebalance算法如下：

* <span class="keyword">Sort</span> PT (all <span class="keyword">partitions</span> <span class="keyword">in</span> topic <span class="keyword">T</span>)
* <span class="keyword">Sort</span> CG(all consumers <span class="keyword">in</span> consumer <span class="keyword">group</span> <span class="keyword">G</span>)
* Let <span class="keyword">i</span> be the <span class="keyword">index</span> <span class="keyword">position</span> <span class="keyword">of</span> Ci <span class="keyword">in</span> CG <span class="keyword">and</span> let <span class="keyword">N</span>=<span class="keyword">size</span>(PT)/<span class="keyword">size</span>(CG)
* Remove <span class="keyword">current</span> entries owned <span class="keyword">by</span> Ci <span class="keyword">from</span> the <span class="keyword">partition</span> owner registry
* Assign <span class="keyword">partitions</span> <span class="keyword">from</span> <span class="keyword">iN</span> <span class="keyword">to</span> (<span class="keyword">i</span>+<span class="number">1</span>)<span class="keyword">N</span>-<span class="number">1</span> <span class="keyword">to</span> consumer Ci
* <span class="keyword">Add</span> newly assigned <span class="keyword">partitions</span> <span class="keyword">to</span> the <span class="keyword">partition</span> owner registry

目前consumer rebalance的控制策略是由每一个consumer通过Zookeeper完成的。具体的控制方式如下：

* <span class="keyword">Register</span> itself <span class="keyword">in</span> the consumer <span class="keyword">id</span> registry <span class="keyword">under</span> its <span class="keyword">group</span>.
* <span class="keyword">Register</span> a watch <span class="keyword">on</span> changes <span class="keyword">under</span> the consumer <span class="keyword">id</span> registry.
* <span class="keyword">Register</span> a watch <span class="keyword">on</span> changes <span class="keyword">under</span> the broker <span class="keyword">id</span> registry.
* <span class="keyword">If</span> the consumer creates a message stream <span class="keyword">using</span> a topic filter, it also registers a watch <span class="keyword">on</span> changes <span class="keyword">under</span> the broker topic registry.
* <span class="keyword">Force</span> itself <span class="keyword">to</span> rebalance <span class="keyword">within</span> <span class="keyword">in</span> its consumer <span class="keyword">group</span>.在这种策略下，每一个consumer或者broker的增加或者减少都会触发consumer rebalance。因为每个consumer只负责调整自己所消费的<span class="keyword">partition</span>，为了保证整个consumer <span class="keyword">group</span>的一致性，所以当一个consumer触发了rebalance时，该consumer <span class="keyword">group</span>内的其它所有consumer也应该同时触发rebalance。

目前（<span class="number">2015</span>-<span class="number">01</span>-<span class="number">19</span>）最新版（<span class="number">0.8</span><span class="number">.2</span>）Kafka采用的是上述方式。

但该方式有不利的方面：
* Herd effect : 任何broker或者consumer的增减都会触发所有的consumer的rebalance
* <span class="keyword">Split</span> Brain : 每个consumer分别单独通过Zookeeper判断哪些<span class="keyword">partition</span> down了，那么不同consumer从Zookeeper“看”到的<span class="keyword">view</span>就可能不一样，这就会造成错误的reblance尝试。而且有可能所有的 consumer都认为rebalance已经完成了，但实际上可能并非如此。

根据Kafka官方文档，Kafka作者正在考虑在还未发布的<span class="number">0.9</span>.x版本中使用中心协调器(coordinator)。 大体思想是选举出一个broker作为coordinator，由它watch Zookeeper，从而判断是否有<span class="keyword">partition</span>或者consumer的增减，然后生成rebalance命令，并检查是否这些rebalance 在所有相关的consumer中被执行成功，如果不成功则重试，若成功则认为此次rebalance成功（这个过程跟<span class="keyword">replication</span> controller非常类似，所以我很奇怪为什么当初设计<span class="keyword">replication</span> controller时没有使用类似方式来解决consumer rebalance的问题）。流程如下：

&lt;img src=<span class="string">"/files/0924-18.jpg"</span>&gt;</span>
</code></pre><h3 id="消息Deliver_guarantee">消息Deliver guarantee</h3><pre><code>通过上文介绍，想必读者已经明天了producer和consumer是如何工作的，以及Kafka是如何做replication的，接下来要讨 论的是Kafka如何确保消息在producer和consumer之间传输。有这么几种可能的delivery guarantee：
</code></pre><ul>
<li>At most once 消息可能会丢，但绝不会重复传输</li>
<li>At least one 消息绝不会丢，但可能会重复传输</li>
<li><p>Exactly once 每条消息肯定会被传输一次且仅传输一次，很多时候这是用户所想要的。Kafka的delivery guarantee semantic非常直接。当producer向broker发送消息时，一旦这条消息被commit，因数replication的存在，它就不会丢。 但是如果producer发送数据给broker后，遇到的网络问题而造成通信中断，那producer就无法判断该条消息是否已经commit。这一点 有点像向一个自动生成primary key的数据库表中插入数据。虽然Kafka无法确定网络故障期间发生了什么，但是producer可以生成一种类似于primary key的东西，发生故障时幂等性的retry多次，这样就做到了Exactly one。截止到目前(Kafka 0.8.2版本，2015-01-25)，这一feature还并未实现，有希望在Kafka未来的版本中实现。（所以目前默认情况下一条消息从producer和broker是确保了At least once，但可通过设置producer异步发送实现At most once）。</p>
<p>  接下来讨论的是消息从broker到consumer的delivery guarantee semantic。（仅针对Kafka consumer high level API）。consumer在从broker读取消息后，可以选择commit，该操作会在Zookeeper中存下该consumer在该 partition下读取的消息的offset。该consumer下一次再读该partition时会从下一条开始读取。如未commit，下一次读取 的开始位置会跟上一次commit之后的开始位置相同。当然可以将consumer设置为autocommit，即consumer一旦读到数据立即自动 commit。如果只讨论这一读取消息的过程，那Kafka是确保了Exactly once。但实际上实际使用中consumer并非读取完数据就结束了，而是要进行进一步处理，而数据处理与commit的顺序在很大程度上决定了消息从broker和consumer的delivery guarantee semantic。</p>
</li>
<li><p>读完消息先commit再处理消息。这种模式下，如果consumer在commit后还没来得及处理消息就crash了，下次重新开始工作后就无法读到刚刚已提交而未处理的消息，这就对应于At most once</p>
</li>
<li>读完消息先处理再commit。这种模式下，如果处理完了消息在commit之前consumer crash了，下次重新开始工作时还会处理刚刚未commit的消息，实际上该消息已经被处理过了。这就对应于At least once。在很多情况使用场景下，消息都有一个primary key，所以消息的处理往往具有幂等性，即多次处理这一条消息跟只处理一次是等效的，那就可以认为是Exactly once。 （人个感觉这种说法有些牵强，毕竟它不是Kafka本身提供的机制，而且primary key本身不保证操作的幂等性。而且实际上我们说delivery guarantee semantic是讨论被处理多少次，而非处理结果怎样，因为处理方式多种多样，我们的系统不应该把处理过程的特性—如是否幂等性，当成Kafka本身的 feature）</li>
<li><p>如果一定要做到Exactly once，就需要协调offset和实际操作的输出。精典的做法是引入两阶段提交。如 果能让offset和操作输入存在同一个地方，会更简洁和通用。这种方式可能更好，因为许多输出系统可能不支持两阶段提交。比如，consumer拿到数 据后可能把数据放到HDFS，如果把最新的offset和数据本身一起写到HDFS，那就可以保证数据的输出和offset的更新要么都完成，要么都不完 成，间接实现Exactly once。（目前就high level API而言，offset是存于Zookeeper中的，无法存于HDFS，而low level API的offset是由自己去维护的，可以将之存于HDFS中）</p>
<p>  总之，Kafka默认保证At least once，并且允许通过设置producer异步提交来实现At most once。而Exactly once要求与目标存储系统协作，幸运的是Kafka提供的offset可以使用这种方式非常直接非常容易。</p>
</li>
</ul>
<h3 id="Benchmark">Benchmark</h3><pre><code>纸上得来终觉浅，绝知些事要躬行。笔者希望能亲自测一下Kafka的性能，而非从网上找一些测试数据。所以笔者曾在<span class="number">0.8</span>发布前两个月做过详细的Kafka0<span class="number">.8</span>性能测试，不过很可惜测试报告不慎丢失。所幸在网上找到了Kafka的创始人之一的Jay Kreps的bechmark。以下描述皆基于该benchmark。（该benchmark基于Kafka0<span class="number">.8</span><span class="number">.1</span>）
</code></pre><h2 id="测试环境">测试环境</h2><pre><code>该benchmark用到了六台机器，机器配置如下
</code></pre><ul>
<li>Intel Xeon 2.5 GHz processor with six cores</li>
<li>Six 7200 RPM SATA drives</li>
<li>32GB of RAM</li>
<li>1Gb Ethernet这6台机器其中3台用来搭建Kafka broker集群，另外3台用来安装Zookeeper及生成测试数据。6个drive都直接以非RAID方式挂载。实际上kafka对机器的需求与Hadoop的类似。</li>
</ul>
<h3 id="producer吞吐率">producer吞吐率</h3><pre><code>该项测试只测producer的吞吐率，也就是数据只被持久化，没有consumer读数据。
</code></pre><h4 id="1个producer线程，无replication">1个producer线程，无replication</h4><pre><code>在这一测试中，创建了一个包含<span class="number">6</span>个partition且没有replication的topic。然后通过一个线程尽可能快的生成<span class="number">50</span> million条比较短（payload100字节长）的消息。测试结果是<span class="number">821</span>,<span class="number">557</span> records/second（<span class="number">78.3</span>MB/second）。

之所以使用短消息，是因为对于消息系统来说这种使用场景更难。因为如果使用MB/second来表征吞吐率，那发送长消息无疑能使得测试结果更好。

整个测试中，都是用每秒钟delivery的消息的数量乘以payload的长度来计算MB/second的，没有把消息的元信息算在内，所以实际的网络 使用量会比这个大。对于本测试来说，每次还需传输额外的<span class="number">22</span>个字节，包括一个可选的key，消息长度描述，CRC等。另外，还包含一些请求相关的 overhead，比如topic，partition，acknowledgement等。这就导致我们比较难判断是否已经达到网卡极限，但是把这些 overhead都算在吞吐率里面应该更合理一些。因此，我们已经基本达到了网卡的极限。

初步观察此结果会认为它比人们所预期的要高很多，尤其当考虑到Kafka要把数据持久化到磁盘当中。实际上，如果使用随机访问数据系统，比如RDBMS， 或者key-velue store，可预期的最高访问频率大概是<span class="number">5000</span>到<span class="number">50000</span>个请求每秒，这和一个好的RPC层所能接受的远程请求量差不多。而该测试中远超于此的原因有 两个。

* Kafka确保写磁盘的过程是线性磁盘I/O，测试中使用的<span class="number">6</span>块廉价磁盘线性I/O的最大吞吐量是<span class="number">822</span>MB/second，这已经远大于<span class="number">1</span>Gb 网卡所能带来的吞吐量了。许多消息系统把数据持久化到磁盘当成是一个开销很大的事情，这是因为他们对磁盘的操作都不是线性I/O。
* 在每一个阶段，Kafka都尽量使用批量处理。如果想了解批处理在I/O操作中的重要性，可以参考David Patterson的”Latency Lags Bandwidth“
</code></pre><h4 id="1个producer线程，3个异步replication">1个producer线程，3个异步replication</h4><pre><code>该项测试与上一测试基本一样，唯一的区别是每个partition有<span class="number">3</span>个replica（所以网络传输的和写入磁盘的总的数据量增加了<span class="number">3</span>倍）。每一 个broker即要写作为leader的partition，也要读（从leader读数据）写（将数据写到磁盘）作为follower的 partition。测试结果为<span class="number">786</span>,<span class="number">980</span> records/second（<span class="number">75.1</span>MB/second）。

该项测试中replication是异步的，也就是说broker收到数据并写入本地磁盘后就acknowledge producer，而不必等所有replica都完成replication。也就是说，如果leader crash了，可能会丢掉一些最新的还未备份的数据。但这也会让message acknowledgement延迟更少，实时性更好。

这项测试说明，replication可以很快。整个集群的写能力可能会由于<span class="number">3</span>倍的replication而只有原来的三分之一，但是对于每一个producer来说吞吐率依然足够好。
</code></pre><h4 id="1个producer线程，3个同步replication">1个producer线程，3个同步replication</h4><pre><code>该项测试与上一测试的唯一区别是replication是同步的，每条消息只有在被<span class="keyword">in</span> sync集合里的所有replica都复制过去后才会被置为committed（此时broker会向producer发送acknowledgement）。在这种模式下，Kafka可以保证即使leader crash了，也不会有数据丢失。测试结果为<span class="number">421</span>,<span class="number">823</span> records/<span class="keyword">second</span>（<span class="number">40.2</span>MB/<span class="keyword">second</span>）。

Kafka同步复制与异步复制并没有本质的不同。leader会始终track follower replica从而监控它们是否还alive，只有所有<span class="keyword">in</span> sync集合里的replica都acknowledge的消息才可能被consumer所消费。而对follower的等待影响了吞吐率。可以通过增大batch size来改善这种情况，但为了避免特定的优化而影响测试结果的可比性，本次测试并没有做这种调整。
</code></pre><h4 id="3个producer,3个异步replication">3个producer,3个异步replication</h4><pre><code>该测试相当于把上文中的<span class="number">1</span>个producer,复制到了<span class="number">3</span>台不同的机器上（在<span class="number">1</span>台机器上跑多个实例对吞吐率的增加不会有太大帮忙，因为网卡已经基本饱和了），这<span class="number">3</span>个producer同时发送数据。整个集群的吞吐率为<span class="number">2</span>,<span class="number">024</span>,<span class="number">032</span> records/second（<span class="number">193</span>,<span class="number">0</span>MB/second）。
</code></pre><h3 id="Producer_Throughput_Vs-_Stored_Data">Producer Throughput Vs. Stored Data</h3><pre><code>消息系统的一个潜在的危险是当数据能都存于内存时性能很好，但当数据量太大无法完全存于内存中时（然后很多消息系统都会删除已经被消费的数据，但当 消费速度比生产速度慢时，仍会造成数据的堆积），数据会被转移到磁盘，从而使得吞吐率下降，这又反过来造成系统无法及时接收数据。这样就非常糟糕，而实际 上很多情景下使用<span class="built_in">queue</span>的目的就是解决数据消费速度和生产速度不一致的问题。

但Kafka不存在这一问题，因为Kafka始终以O（<span class="number">1</span>）的时间复杂度将数据持久化到磁盘，所以其吞吐率不受磁盘上所存储的数据量的影响。为了验证这一特性，做了一个长时间的大数据量的测试，下图是吞吐率与数据量大小的关系图。

&lt;img src=<span class="string">"/files/0924-19.jpg"</span>&gt;

上图中有一些variance的存在，并可以明显看到，吞吐率并不受磁盘上所存数据量大小的影响。实际上从上图可以看到，当磁盘数据量达到<span class="number">1</span>TB时，吞吐率和磁盘数据只有几百MB时没有明显区别。

这个variance是由Linux I/O管理造成的，它会把数据缓存起来再批量flush。上图的测试结果是在生产环境中对Kafka集群做了些tuning后得到的，这些tuning方法可参考这里。
</code></pre><h3 id="consumer吞吐率">consumer吞吐率</h3><pre><code>需要注意的是，replication <span class="built_in">factor</span>并不会影响consumer的吞吐率测试，因为consumer只会从每个partition的leader读数据，而与 replicaiton <span class="built_in">factor</span>无关。同样，consumer吞吐率也与同步复制还是异步复制无关。
</code></pre><h4 id="1个consumer">1个consumer</h4><pre><code>该测试从有<span class="number">6</span>个partition，<span class="number">3</span>个replication的topic消费<span class="number">50</span> million的消息。测试结果为<span class="number">940</span>,<span class="number">521</span> records/second（<span class="number">89.7</span>MB/second）。

可以看到，Kafkar的consumer是非常高效的。它直接从broker的文件系统里读取文件块。Kafka使用sendfile API来直接通过操作系统直接传输，而不用把数据拷贝到用户空间。该项测试实际上从<span class="built_in">log</span>的起始处开始读数据，所以它做了真实的I/O。在生产环境下，consumer可以直接读取producer刚刚写下的数据（它可能还在缓存中）。实际上，如果在生产环境下跑I/O stat，你可以看到基本上没有物理“读”。也就是说生产环境下consumer的吞吐率会比该项测试中的要高。
</code></pre><h4 id="3个consumer">3个consumer</h4><pre><code>将上面的consumer复制到<span class="number">3</span>台不同的机器上，并且并行运行它们（从同一个topic上消费数据）。测试结果为<span class="number">2</span>,<span class="number">615</span>,<span class="number">968</span> records/second（<span class="number">249.5</span>MB/second）。

正如所预期的那样，consumer的吞吐率几乎线性增涨。
</code></pre><h3 id="Producer_and_Consumer">Producer and Consumer</h3><pre><code>上面的测试只是把producer和consumer分开测试，而该项测试同时运行producer和consumer，这更接近使用场景。实际上目前的replication系统中follower就相当于consumer在工作。

该项测试，在具有<span class="number">6</span>个partition和<span class="number">3</span>个replica的topic上同时使用<span class="number">1</span>个producer和<span class="number">1</span>个consumer，并且使用异步复制。测试结果为<span class="number">795</span>,<span class="number">064</span> records/second（<span class="number">75.8</span>MB/second）。

可以看到，该项测试结果与单独测试<span class="number">1</span>个producer时的结果几乎一致。所以说consumer非常轻量级。
</code></pre><h3 id="消息长度对吞吐率的影响">消息长度对吞吐率的影响</h3><pre><code>上面的所有测试都基于短消息（payload <span class="number">100</span>字节），而正如上文所说，短消息对Kafka来说是更难处理的使用方式，可以预期，随着消息长度的增大，records/<span class="keyword">second</span>会减小，但 MB/<span class="keyword">second</span>会有所提高。下图是records/<span class="keyword">second</span>与消息长度的关系图。

&lt;img src=<span class="string">"/files/0924-20.jpg"</span>&gt;

正如我们所预期的那样，随着消息长度的增加，每秒钟所能发送的消息的数量逐渐减小。但是如果看每秒钟发送的消息的总大小，它会随着消息长度的增加而增加，如下图所示。

&lt;img src=<span class="string">"/files/0924-21.jpg"</span>&gt;

从上图可以看出，当消息长度为<span class="number">10</span>字节时，因为要频繁入队，花了太多时间获取锁，CPU成了瓶颈，并不能充分利用带宽。但从<span class="number">100</span>字节开始，我们可以看到带宽的使用逐渐趋于饱和（虽然MB/<span class="keyword">second</span>还是会随着消息长度的增加而增加，但增加的幅度也越来越小）。
</code></pre><h3 id="端到端的Latency">端到端的Latency</h3><pre><code>上文中讨论了吞吐率，那消息传输的latency如何呢？也就是说消息从producer到consumer需要多少时间呢？该项测试创建<span class="number">1</span>个producer和<span class="number">1</span>个consumer并反复计时。结果是，<span class="number">2</span> ms (median), <span class="number">3</span>ms (<span class="number">99</span>th percentile, <span class="number">14</span>ms (<span class="number">99.9</span>th percentile)。

（这里并没有说明topic有多少个partition，也没有说明有多少个replica，replication是同步还是异步。实际上这会极大影响 producer发送的消息被commit的latency，而只有committed的消息才能被consumer所消费，所以它会最终影响端到端的 latency）
</code></pre><h3 id="重现该benchmark">重现该benchmark</h3><pre><code>如果读者想要在自己的机器上重现本次benchmark测试，可以参考本次测试的配置和所使用的命令。

实际上Kafka Distribution提供了producer性能测试工具，可通过bin/kafka-producer-perf-<span class="keyword">test</span>.<span class="keyword">sh</span>脚本来启动。所使用的命令如下
</code></pre><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">Producer</span><br><span class="line">Setup</span><br><span class="line">bin/kafka-topics.sh --zookeeper esv4-hcl197.grid.linkedin.com:<span class="number">2181</span> --create --topic test-rep-one --partitions <span class="number">6</span> --replication-factor <span class="number">1</span></span><br><span class="line">bin/kafka-topics.sh --zookeeper esv4-hcl197.grid.linkedin.com:<span class="number">2181</span> --create --topic test --partitions <span class="number">6</span> --replication-factor <span class="number">3</span></span><br><span class="line"> </span><br><span class="line">Single thread, no replication</span><br><span class="line"> </span><br><span class="line">bin/kafka-run-<span class="keyword">class</span>.sh org.apache.kafka.clients.tools.ProducerPerformance test7 <span class="number">50000000</span> <span class="number">100</span> -<span class="number">1</span> acks=<span class="number">1</span> bootstrap.servers=esv4-hcl198.grid.linkedin.com:<span class="number">9092</span> buffer.memory=<span class="number">67108864</span> batch.size=<span class="number">8196</span></span><br><span class="line"> </span><br><span class="line">Single-thread, async <span class="number">3</span>x replication</span><br><span class="line"> </span><br><span class="line">bin/kafktopics.sh --zookeeper esv4-hcl197.grid.linkedin.com:<span class="number">2181</span> --create --topic test --partitions <span class="number">6</span> --replication-factor <span class="number">3</span></span><br><span class="line">bin/kafka-run-<span class="keyword">class</span>.sh org.apache.kafka.clients.tools.ProducerPerformance test6 <span class="number">50000000</span> <span class="number">100</span> -<span class="number">1</span> acks=<span class="number">1</span> bootstrap.servers=esv4-hcl198.grid.linkedin.com:<span class="number">9092</span> buffer.memory=<span class="number">67108864</span> batch.size=<span class="number">8196</span></span><br><span class="line"> </span><br><span class="line">Single-thread, sync <span class="number">3</span>x replication</span><br><span class="line"> </span><br><span class="line">bin/kafka-run-<span class="keyword">class</span>.sh org.apache.kafka.clients.tools.ProducerPerformance test <span class="number">50000000</span> <span class="number">100</span> -<span class="number">1</span> acks=-<span class="number">1</span> bootstrap.servers=esv4-hcl198.grid.linkedin.com:<span class="number">9092</span> buffer.memory=<span class="number">67108864</span> batch.size=<span class="number">64000</span></span><br><span class="line"> </span><br><span class="line">Three Producers, <span class="number">3</span>x async replication</span><br><span class="line">bin/kafka-run-<span class="keyword">class</span>.sh org.apache.kafka.clients.tools.ProducerPerformance test <span class="number">50000000</span> <span class="number">100</span> -<span class="number">1</span> acks=<span class="number">1</span> bootstrap.servers=esv4-hcl198.grid.linkedin.com:<span class="number">9092</span> buffer.memory=<span class="number">67108864</span> batch.size=<span class="number">8196</span></span><br><span class="line"> </span><br><span class="line">Throughput Versus Stored Data</span><br><span class="line"> </span><br><span class="line">bin/kafka-run-<span class="keyword">class</span>.sh org.apache.kafka.clients.tools.ProducerPerformance test <span class="number">50000000000</span> <span class="number">100</span> -<span class="number">1</span> acks=<span class="number">1</span> bootstrap.servers=esv4-hcl198.grid.linkedin.com:<span class="number">9092</span> buffer.memory=<span class="number">67108864</span> batch.size=<span class="number">8196</span></span><br><span class="line"> </span><br><span class="line">Effect of message size</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> i in <span class="number">10</span> <span class="number">100</span> <span class="number">1000</span> <span class="number">10000</span> <span class="number">100000</span>;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">echo <span class="string">""</span></span><br><span class="line">echo $i</span><br><span class="line">bin/kafka-run-<span class="keyword">class</span>.sh org.apache.kafka.clients.tools.ProducerPerformance test $((<span class="number">1000</span>*<span class="number">1024</span>*<span class="number">1024</span>/$i)) $i -<span class="number">1</span> acks=<span class="number">1</span> bootstrap.servers=esv4-hcl198.grid.linkedin.com:<span class="number">9092</span> buffer.memory=<span class="number">67108864</span> batch.size=<span class="number">128000</span></span><br><span class="line">done;</span><br><span class="line"> </span><br><span class="line">Consumer</span><br><span class="line">Consumer throughput</span><br><span class="line"> </span><br><span class="line">bin/kafka-consumer-perf-test.sh --zookeeper esv4-hcl197.grid.linkedin.com:<span class="number">2181</span> --messages <span class="number">50000000</span> --topic test --threads <span class="number">1</span></span><br><span class="line"> </span><br><span class="line"><span class="number">3</span> Consumers</span><br><span class="line"> </span><br><span class="line">On three servers, run:</span><br><span class="line">bin/kafka-consumer-perf-test.sh --zookeeper esv4-hcl197.grid.linkedin.com:<span class="number">2181</span> --messages <span class="number">50000000</span> --topic test --threads <span class="number">1</span></span><br><span class="line"> </span><br><span class="line">End-to-end Latency</span><br><span class="line"> </span><br><span class="line">bin/kafka-run-<span class="keyword">class</span>.sh kafka.tools.TestEndToEndLatency esv4-hcl198.grid.linkedin.com:<span class="number">9092</span> esv4-hcl197.grid.linkedin.com:<span class="number">2181</span> test <span class="number">5000</span></span><br><span class="line"> </span><br><span class="line">Producer and consumer</span><br><span class="line"> </span><br><span class="line">bin/kafka-run-<span class="keyword">class</span>.sh org.apache.kafka.clients.tools.ProducerPerformance test <span class="number">50000000</span> <span class="number">100</span> -<span class="number">1</span> acks=<span class="number">1</span> bootstrap.servers=esv4-hcl198.grid.linkedin.com:<span class="number">9092</span> buffer.memory=<span class="number">67108864</span> batch.size=<span class="number">8196</span></span><br><span class="line"> </span><br><span class="line">bin/kafka-consumer-perf-test.sh --zookeeper esv4-hcl197.grid.linkedin.com:<span class="number">2181</span> --messages <span class="number">50000000</span> --topic test --threads <span class="number">1</span></span><br></pre></td></tr></table></figure>
<pre><code>broker配置如下:
</code></pre><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line">############################# Server Basics #############################</span><br><span class="line"> </span><br><span class="line"># The id of the broker. This must be <span class="operator"><span class="keyword">set</span> <span class="keyword">to</span> a <span class="keyword">unique</span> <span class="built_in">integer</span> <span class="keyword">for</span> <span class="keyword">each</span> broker.</span><br><span class="line">broker.<span class="keyword">id</span>=<span class="number">0</span></span><br><span class="line"> </span><br><span class="line">############################# Socket <span class="keyword">Server</span> <span class="keyword">Settings</span> #############################</span><br><span class="line"> </span><br><span class="line"># The port the socket <span class="keyword">server</span> listens <span class="keyword">on</span></span><br><span class="line">port=<span class="number">9092</span></span><br><span class="line"> </span><br><span class="line"># Hostname the broker will bind <span class="keyword">to</span> <span class="keyword">and</span> advertise <span class="keyword">to</span> producers <span class="keyword">and</span> consumers.</span><br><span class="line"># <span class="keyword">If</span> <span class="keyword">not</span> <span class="keyword">set</span>, the <span class="keyword">server</span> will bind <span class="keyword">to</span> all interfaces <span class="keyword">and</span> advertise the <span class="keyword">value</span> returned <span class="keyword">from</span></span><br><span class="line"># <span class="keyword">from</span> <span class="keyword">java</span>.net.InetAddress.getCanonicalHostName().</span><br><span class="line">#host.<span class="keyword">name</span>=localhost</span><br><span class="line"> </span><br><span class="line"># The <span class="built_in">number</span> <span class="keyword">of</span> threads handling network requests</span><br><span class="line"><span class="keyword">num</span>.network.threads=<span class="number">4</span></span><br><span class="line"> </span><br><span class="line"># The <span class="built_in">number</span> <span class="keyword">of</span> threads doing disk <span class="keyword">I</span>/O</span><br><span class="line"><span class="keyword">num</span>.io.threads=<span class="number">8</span></span><br><span class="line"> </span><br><span class="line"># The send buffer (SO_SNDBUF) used <span class="keyword">by</span> the socket <span class="keyword">server</span></span><br><span class="line">socket.send.buffer.<span class="keyword">bytes</span>=<span class="number">1048576</span></span><br><span class="line"> </span><br><span class="line"># The receive buffer (SO_RCVBUF) used <span class="keyword">by</span> the socket <span class="keyword">server</span></span><br><span class="line">socket.receive.buffer.<span class="keyword">bytes</span>=<span class="number">1048576</span></span><br><span class="line"> </span><br><span class="line"># The maximum <span class="keyword">size</span> <span class="keyword">of</span> a request that the socket <span class="keyword">server</span> will <span class="keyword">accept</span> (<span class="keyword">protection</span> against OOM)</span><br><span class="line">socket.request.<span class="keyword">max</span>.<span class="keyword">bytes</span>=<span class="number">104857600</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">############################# <span class="keyword">Log</span> Basics #############################</span><br><span class="line"> </span><br><span class="line"># The <span class="keyword">directory</span> <span class="keyword">under</span> which <span class="keyword">to</span> <span class="keyword">store</span> <span class="keyword">log</span> files</span><br><span class="line"><span class="keyword">log</span>.dirs=/grid/a/dfs-<span class="keyword">data</span>/kafka-<span class="keyword">logs</span>,/grid/b/dfs-<span class="keyword">data</span>/kafka-<span class="keyword">logs</span>,/grid/<span class="keyword">c</span>/dfs-<span class="keyword">data</span>/kafka-<span class="keyword">logs</span>,/grid/<span class="keyword">d</span>/dfs-<span class="keyword">data</span>/kafka-<span class="keyword">logs</span>,/grid/<span class="keyword">e</span>/dfs-<span class="keyword">data</span>/kafka-<span class="keyword">logs</span>,/grid/<span class="keyword">f</span>/dfs-<span class="keyword">data</span>/kafka-<span class="keyword">logs</span></span><br><span class="line"> </span><br><span class="line"># The <span class="built_in">number</span> <span class="keyword">of</span> <span class="keyword">logical</span> <span class="keyword">partitions</span> per topic per <span class="keyword">server</span>. More <span class="keyword">partitions</span> <span class="keyword">allow</span> greater parallelism</span><br><span class="line"># <span class="keyword">for</span> consumption, but also mean more files.</span><br><span class="line"><span class="keyword">num</span>.<span class="keyword">partitions</span>=<span class="number">8</span></span><br><span class="line"> </span><br><span class="line">############################# <span class="keyword">Log</span> <span class="keyword">Flush</span> <span class="keyword">Policy</span> #############################</span><br><span class="line"> </span><br><span class="line"># The <span class="keyword">following</span> configurations control the <span class="keyword">flush</span> <span class="keyword">of</span> <span class="keyword">data</span> <span class="keyword">to</span> disk. This <span class="keyword">is</span> the most</span><br><span class="line"># important <span class="keyword">performance</span> knob <span class="keyword">in</span> kafka.</span><br><span class="line"># There <span class="keyword">are</span> a few important trade-offs here:</span><br><span class="line">#    <span class="number">1.</span> Durability: Unflushed <span class="keyword">data</span> <span class="keyword">is</span> <span class="keyword">at</span> greater risk <span class="keyword">of</span> loss <span class="keyword">in</span> the <span class="keyword">event</span> <span class="keyword">of</span> a crash.</span><br><span class="line">#    <span class="number">2.</span> Latency: <span class="keyword">Data</span> <span class="keyword">is</span> <span class="keyword">not</span> made available <span class="keyword">to</span> consumers <span class="keyword">until</span> it <span class="keyword">is</span> flushed (which adds latency).</span><br><span class="line">#    <span class="number">3.</span> Throughput: The <span class="keyword">flush</span> <span class="keyword">is</span> generally the most expensive operation. </span><br><span class="line"># The <span class="keyword">settings</span> below <span class="keyword">allow</span> one <span class="keyword">to</span> configure the <span class="keyword">flush</span> <span class="keyword">policy</span> <span class="keyword">to</span> <span class="keyword">flush</span> <span class="keyword">data</span> <span class="keyword">after</span> a <span class="keyword">period</span> <span class="keyword">of</span> <span class="keyword">time</span> <span class="keyword">or</span></span><br><span class="line"># every <span class="keyword">N</span> messages (<span class="keyword">or</span> <span class="keyword">both</span>). This can be done <span class="keyword">globally</span> <span class="keyword">and</span> overridden <span class="keyword">on</span> a per-topic basis.</span><br><span class="line"> </span><br><span class="line"># Per-topic overrides <span class="keyword">for</span> <span class="keyword">log</span>.<span class="keyword">flush</span>.<span class="built_in">interval</span>.ms</span><br><span class="line">#<span class="keyword">log</span>.<span class="keyword">flush</span>.intervals.ms.per.topic=topic1:<span class="number">1000</span>, topic2:<span class="number">3000</span></span><br><span class="line"> </span><br><span class="line">############################# <span class="keyword">Log</span> <span class="keyword">Retention</span> <span class="keyword">Policy</span> #############################</span><br><span class="line"> </span><br><span class="line"># The <span class="keyword">following</span> configurations control the disposal <span class="keyword">of</span> <span class="keyword">log</span> segments. The <span class="keyword">policy</span> can</span><br><span class="line"># be <span class="keyword">set</span> <span class="keyword">to</span> <span class="keyword">delete</span> segments <span class="keyword">after</span> a <span class="keyword">period</span> <span class="keyword">of</span> <span class="keyword">time</span>, <span class="keyword">or</span> <span class="keyword">after</span> a given <span class="keyword">size</span> has accumulated.</span><br><span class="line"># A <span class="keyword">segment</span> will be deleted <span class="keyword">whenever</span> *either* <span class="keyword">of</span> these criteria <span class="keyword">are</span> met. Deletion <span class="keyword">always</span> happens</span><br><span class="line"># <span class="keyword">from</span> the <span class="keyword">end</span> <span class="keyword">of</span> the <span class="keyword">log</span>.</span><br><span class="line"> </span><br><span class="line"># The <span class="keyword">minimum</span> age <span class="keyword">of</span> a <span class="keyword">log</span> <span class="keyword">file</span> <span class="keyword">to</span> be eligible <span class="keyword">for</span> deletion</span><br><span class="line"><span class="keyword">log</span>.<span class="keyword">retention</span>.hours=<span class="number">168</span></span><br><span class="line"> </span><br><span class="line"># A <span class="keyword">size</span>-based <span class="keyword">retention</span> <span class="keyword">policy</span> <span class="keyword">for</span> <span class="keyword">logs</span>. Segments <span class="keyword">are</span> pruned <span class="keyword">from</span> the <span class="keyword">log</span> <span class="keyword">as</span> <span class="keyword">long</span> <span class="keyword">as</span> the remaining</span><br><span class="line"># segments don<span class="string">'t drop below log.retention.bytes.</span><br><span class="line">#log.retention.bytes=1073741824</span><br><span class="line"> </span><br><span class="line"># The maximum size of a log segment file. When this size is reached a new log segment will be created.</span><br><span class="line">log.segment.bytes=536870912</span><br><span class="line"> </span><br><span class="line"># The interval at which log segments are checked to see if they can be deleted according </span><br><span class="line"># to the retention policies</span><br><span class="line">log.cleanup.interval.mins=1</span><br><span class="line"> </span><br><span class="line">############################# Zookeeper #############################</span><br><span class="line"> </span><br><span class="line"># Zookeeper connection string (see zookeeper docs for details).</span><br><span class="line"># This is a comma separated host:port pairs, each corresponding to a zk</span><br><span class="line"># server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".</span><br><span class="line"># You can also append an optional chroot string to the urls to specify the</span><br><span class="line"># root directory for all kafka znodes.</span><br><span class="line">zookeeper.connect=esv4-hcl197.grid.linkedin.com:2181</span><br><span class="line"> </span><br><span class="line"># Timeout in ms for connecting to zookeeper</span><br><span class="line">zookeeper.connection.timeout.ms=1000000</span><br><span class="line"> </span><br><span class="line"># metrics reporter properties</span><br><span class="line">kafka.metrics.polling.interval.secs=5</span><br><span class="line">kafka.metrics.reporters=kafka.metrics.KafkaCSVMetricsReporter</span><br><span class="line">kafka.csv.metrics.dir=/tmp/kafka_metrics</span><br><span class="line"># Disable csv reporting by default.</span><br><span class="line">kafka.csv.metrics.reporter.enabled=false</span><br><span class="line"> </span><br><span class="line">replica.lag.max.messages=10000000</span></span></span><br></pre></td></tr></table></figure>
<h2 id="参考">参考</h2><ul>
<li>使用消息队列的 10 个理由</li>
<li>Apache Kafka</li>
<li>Efficient data transfer through zero copy</li>
<li>Benchmarking Apache Kafka: 2 Million Writes Per Second (On Three Cheap Machines)</li>
<li>Kafka 0.8 Producer Performance</li>
</ul>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2015/11/10/如何生成每秒百万级别的HTTP请求/" itemprop="url">
                如何生成每秒百万级别的HTTP请求
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2015-11-10T22:30:37+08:00" content="2015-11-10">
            2015-11-10
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2015/11/10/如何生成每秒百万级别的HTTP请求/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2015/11/10/如何生成每秒百万级别的HTTP请求/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>本文是构建能够每秒处理 3 百万请求的高性能 Web 集群系列文章的第一篇。它记录了我使用负载生成器工具的一些经历，希望它能帮助每一个像我一样不得不使用这些工具的人节省时间。</p>
<p>负载生成器是一些生成用于测试的流量的程序。它们可以向你展示服务器在高负载的情况下的性能，以及让你能够找出服务器可能存在的问题。通过负载测试了解服务器的缺点，是测试服务器弹性以及未雨绸缪的好方法。</p>
<p>负载生成工具（Load-Generating Tools）</p>
<p>在进行负责测试时要牢记一件重要的事：你能在 Linux 上建立多少个 socket 连接。这个限制是硬编码在内核里的，最典型的就是临时 W 端口的限制。（在某种程度上）你可以在 /etc/sysctl.conf 里扩展它。但是基本上，一台 Linux 机器只能同时打开大约 64,000 个 socket 。因此在负载测试时，我们不得不通过在单一的连接上尽可能多地发出请求来充分利用 socket 。 除此之外，我们还需要不止一台的机器来产生负载。否则，负载生成器会把可用的 socket 占用导致不能产生足够的负载。</p>
<p>我一开始用的是‘ab’，Apache Bench 。它是我所知道的 http 基准测试工具中最简单、最通用的。并且它是 Apache 附带的产品，因此它可能已经存在于你的系统中。不幸的是，我在使用它的时候每秒大约只能生成 900 个请求。虽然我见过其他人使用它每秒能达到 2,000 个请求，但我可以立即告诉你，‘ab’并不适合我们的基准测试。</p>
<h1 id="Httperf">Httperf</h1><p>接着，我尝试了 ‘httperf’。这个工具更强大，但是它依然相对简单并且功能有限。要算出每秒生产了多少个请求并不是仅传递参数那么简单。经过我的多次尝试，获取了每秒超过几百请求的结果。例如：</p>
<p>它以每秒 1,000 个的速率创建了 100,000 个会话（session）。每次会话发起 5 次请求，时间间隔为 2 秒。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">httperf --hog --server=<span class="number">192.168</span><span class="number">.122</span><span class="number">.10</span> --wsess=<span class="number">100000</span>,<span class="number">5</span>,<span class="number">2</span> --rate <span class="number">1000</span> --timeout <span class="number">5</span></span><br><span class="line"></span><br><span class="line">Total: connections <span class="number">117557</span> requests <span class="number">219121</span> replies <span class="number">116697</span> test-duration <span class="number">111.423</span> s</span><br><span class="line"></span><br><span class="line">Connection rate: <span class="number">1055.0</span> conn/s (<span class="number">0.9</span> ms/conn, &lt;=<span class="number">1022</span> concurrent connections)</span><br><span class="line">Connection time [ms]: min <span class="number">0.3</span> avg <span class="number">865.9</span> max <span class="number">7912.5</span> median <span class="number">459.5</span> stddev <span class="number">993.1</span></span><br><span class="line">Connection time [ms]: connect <span class="number">31.1</span></span><br><span class="line">Connection length [replies/conn]: <span class="number">1.000</span></span><br><span class="line"></span><br><span class="line">Request rate: <span class="number">1966.6</span> req/s (<span class="number">0.5</span> ms/req)</span><br><span class="line">Request size [B]: <span class="number">91.0</span></span><br><span class="line"></span><br><span class="line">Reply rate [replies/s]: min <span class="number">59.4</span> avg <span class="number">1060.3</span> max <span class="number">1639.7</span> stddev <span class="number">475.2</span> (<span class="number">22</span> samples)</span><br><span class="line">Reply time [ms]: response <span class="number">56.3</span> transfer <span class="number">0.0</span></span><br><span class="line">Reply size [B]: header <span class="number">267.0</span> content <span class="number">18.0</span> footer <span class="number">0.0</span> (total <span class="number">285.0</span>)</span><br><span class="line">Reply status: <span class="number">1</span>xx=<span class="number">0</span> <span class="number">2</span>xx=<span class="number">116697</span> <span class="number">3</span>xx=<span class="number">0</span> <span class="number">4</span>xx=<span class="number">0</span> <span class="number">5</span>xx=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">CPU time [s]: user <span class="number">9.68</span> system <span class="number">101.72</span> (user <span class="number">8.7</span>% system <span class="number">91.3</span>% total <span class="number">100.0</span>%)</span><br><span class="line">Net I/O: <span class="number">467.5</span> KB/s (<span class="number">3.8</span>*<span class="number">10</span>^<span class="number">6</span> bps)</span><br></pre></td></tr></table></figure>
<p>最终，我使用这些设置达到了每秒 6,622 个连接：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">httperf --hog --server <span class="number">192.168</span><span class="number">.122</span><span class="number">.10</span> --num-conn <span class="number">100000</span> --ra <span class="number">20000</span> --timeout <span class="number">5</span></span><br></pre></td></tr></table></figure>
<p>（总共创建了 100,000 个连接，并且以每秒 20,000 个连接的固定速率创建）</p>
<p>它还有一些潜在的优势，并且拥有比‘ab‘更多的特性。但它不是我要用在这个项目里的重量级工具。我需要的是能够支持分布式多负载测试节点的工具。因此，我的下一个尝试是：Jmeter。</p>
<h1 id="Apache_Jmeter">Apache Jmeter</h1><p>这是一个功能齐全的 web 应用测试套件，它可以模拟真实用户的所有行为。你可以使用 Jmeter 的代理去访问你的网站，进行点击、登陆、模仿用户可以做的所有行为。Jemeter 会把这些行为记录下来作为测试用例。然后 Jmeter 会反复执行这些动作来模拟你想要的用户数量。尽管配置 Jmeter 比 ‘ab‘ 和 ’httperf‘ 复杂得多，但它是一个很有趣的工具！</p>
<p>根据我的测试，它每秒可以产生 14,000 个请求！这绝对是一个好的进展。</p>
<p>我使用了 Googlle Code project 上的一些插件，并且使用它们的“Stepping Threads”和“HTTP RAW”请求，最终每秒大约可以产生 30,000 个请求！但这已经达到极限了，所以还要寻找另一个工具。这里有一个我之前的 Jmeter 配置，希望可以帮助到其他人。虽然这个配置离完美相差甚远，但有时它可以满足你的要求。</p>
<h1 id="Tsung:_重型的（heavy-duty）、分布式的、多协议测试工具">Tsung: 重型的（heavy-duty）、分布式的、多协议测试工具</h1><p>它每秒基本可以产生 40,000 个请求，这绝对是我们想要的工具。类似于 Jmeter，你可以把一些行为记录下来在测试时运行，并且可以测试大多数的协议。比如 SSL、HHTP、WebDAV、SOAP、PostgreSQL、MySQL、LDAP 和 Jabber/XMPP。与 Jmeter 不同的是，它没有让人感到迷茫的 GUI 设置，它仅有一个 XML 配置文件，和一些你选择的分布式节点的 SSH 密钥。它的简洁和效率对我的吸引力，完全不亚于它的健壮性和可扩展性。我发现它是一个很强大的工具，在正确的配置下它可以每秒产生百万级的 HTTP 请求。</p>
<p>除此之外，Tsung 还可以在 html 上产生图表以及输入你的测试的详细报告。测试的结果通俗易懂，并且你甚至可以把这些图片展示给你的 boss 看！</p>
<p>在这个系列文章的剩余部分，我还会讲解这个工具。现在你可以继续浏览下面的配置说明，或者直接跳到下一页。</p>
<p>在 CentOS 6.2 上安装 Tsung</p>
<p>首先，你要安装（Erlang 需要的） EPEL 源。因此，在进行下一步之前要把它安装好。安装完后，继续安装你用来产生负载的每个节点需要的包。如果你还没有在节点之间建立无密码 SSH 密钥（passwordless SSH key），那么请建立之。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install erlang perl perl-RRD-Simple<span class="class">.noarch</span> perl-Log-Log4perl-RRDs<span class="class">.noarch</span> gnuplot perl-Template-Toolkit firefox</span><br></pre></td></tr></table></figure>
<p>从 Github 或者 Tsung 的官网上下载最新的 Tsung。</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget <span class="string">http:</span><span class="comment">//tsung.erlang-projects.org/dist/tsung-1.4.2.tar.gz</span></span><br></pre></td></tr></table></figure>
<p>解压并且编译。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar zxfv  tsung-<span class="number">1.4</span><span class="number">.2</span>.tar.gz</span><br><span class="line">cd tsung-<span class="number">1.4</span><span class="number">.2</span></span><br><span class="line">./configure &amp;&amp; make &amp;&amp; make install</span><br></pre></td></tr></table></figure>
<p>把示例配置复制到 ~/.tsung 目录里。这是 Tsung 的配置文件和日志文件的存放地方。</p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp  <span class="regexp">/usr/</span>share<span class="regexp">/doc/</span>tsung<span class="regexp">/examples/</span>http_simple.xml <span class="regexp">/root/</span>.tsung<span class="regexp">/tsung.xml</span></span><br></pre></td></tr></table></figure>
<p>你可以根据你的需求去编辑这个配置文件，或者使用我的配置文件。经过大量的尝试以及失败后，我目前的配置文件在使用 7 个分布式节点时可以每秒产生 5 百万个 HTTP 请求。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="pi">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="doctype">&lt;!DOCTYPE tsung SYSTEM "/usr/share/tsung/tsung-1.0.dtd"&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">tsung</span> <span class="attribute">loglevel</span>=<span class="value">"notice"</span> <span class="attribute">version</span>=<span class="value">"1.0"</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="title">clients</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">client</span> <span class="attribute">host</span>=<span class="value">"localhost"</span> <span class="attribute">weight</span>=<span class="value">"1"</span> <span class="attribute">cpu</span>=<span class="value">"10"</span> <span class="attribute">maxusers</span>=<span class="value">"40000"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">ip</span> <span class="attribute">value</span>=<span class="value">"192.168.122.2"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">client</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">client</span> <span class="attribute">host</span>=<span class="value">"loadnode1"</span> <span class="attribute">weight</span>=<span class="value">"1"</span> <span class="attribute">cpu</span>=<span class="value">"9"</span> <span class="attribute">maxusers</span>=<span class="value">"40000"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">ip</span> <span class="attribute">value</span>=<span class="value">"192.168.122.2"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">client</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">client</span> <span class="attribute">host</span>=<span class="value">"loadnode2"</span> <span class="attribute">weight</span>=<span class="value">"1"</span> <span class="attribute">maxusers</span>=<span class="value">"40000"</span> <span class="attribute">cpu</span>=<span class="value">"8"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">ip</span> <span class="attribute">value</span>=<span class="value">"192.168.122.3"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">client</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">client</span> <span class="attribute">host</span>=<span class="value">"loadnode3"</span> <span class="attribute">weight</span>=<span class="value">"1"</span> <span class="attribute">maxusers</span>=<span class="value">"40000"</span> <span class="attribute">cpu</span>=<span class="value">"9"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">ip</span> <span class="attribute">value</span>=<span class="value">"192.168.122.21"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">client</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">client</span> <span class="attribute">host</span>=<span class="value">"loadnode4"</span> <span class="attribute">weight</span>=<span class="value">"1"</span> <span class="attribute">maxusers</span>=<span class="value">"40000"</span> <span class="attribute">cpu</span>=<span class="value">"9"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">ip</span> <span class="attribute">value</span>=<span class="value">"192.168.122.11"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">client</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">client</span> <span class="attribute">host</span>=<span class="value">"loadnode5"</span> <span class="attribute">weight</span>=<span class="value">"1"</span> <span class="attribute">maxusers</span>=<span class="value">"40000"</span> <span class="attribute">cpu</span>=<span class="value">"9"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">ip</span> <span class="attribute">value</span>=<span class="value">"192.168.122.12"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">client</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">client</span> <span class="attribute">host</span>=<span class="value">"loadnode6"</span> <span class="attribute">weight</span>=<span class="value">"1"</span> <span class="attribute">maxusers</span>=<span class="value">"40000"</span> <span class="attribute">cpu</span>=<span class="value">"9"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">ip</span> <span class="attribute">value</span>=<span class="value">"192.168.122.13"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">client</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">client</span> <span class="attribute">host</span>=<span class="value">"loadnode7"</span> <span class="attribute">weight</span>=<span class="value">"1"</span> <span class="attribute">maxusers</span>=<span class="value">"40000"</span> <span class="attribute">cpu</span>=<span class="value">"9"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">ip</span> <span class="attribute">value</span>=<span class="value">"192.168.122.14"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">client</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">clients</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="title">servers</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">server</span> <span class="attribute">host</span>=<span class="value">"192.168.122.10"</span> <span class="attribute">port</span>=<span class="value">"80"</span> <span class="attribute">type</span>=<span class="value">"tcp"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">servers</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="title">load</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">arrivalphase</span> <span class="attribute">phase</span>=<span class="value">"1"</span> <span class="attribute">duration</span>=<span class="value">"10"</span> <span class="attribute">unit</span>=<span class="value">"minute"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">users</span> <span class="attribute">maxnumber</span>=<span class="value">"15000"</span> <span class="attribute">arrivalrate</span>=<span class="value">"8"</span> <span class="attribute">unit</span>=<span class="value">"second"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">arrivalphase</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="title">arrivalphase</span> <span class="attribute">phase</span>=<span class="value">"2"</span> <span class="attribute">duration</span>=<span class="value">"10"</span> <span class="attribute">unit</span>=<span class="value">"minute"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">users</span> <span class="attribute">maxnumber</span>=<span class="value">"15000"</span> <span class="attribute">arrivalrate</span>=<span class="value">"8"</span> <span class="attribute">unit</span>=<span class="value">"second"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">arrivalphase</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="title">arrivalphase</span> <span class="attribute">phase</span>=<span class="value">"3"</span> <span class="attribute">duration</span>=<span class="value">"30"</span> <span class="attribute">unit</span>=<span class="value">"minute"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">users</span> <span class="attribute">maxnumber</span>=<span class="value">"20000"</span> <span class="attribute">arrivalrate</span>=<span class="value">"3"</span> <span class="attribute">unit</span>=<span class="value">"second"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">arrivalphase</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="title">load</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="title">sessions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">session</span> <span class="attribute">probability</span>=<span class="value">"100"</span> <span class="attribute">name</span>=<span class="value">"ab"</span> <span class="attribute">type</span>=<span class="value">"ts_http"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">for</span> <span class="attribute">from</span>=<span class="value">"1"</span> <span class="attribute">to</span>=<span class="value">"10000000"</span> <span class="attribute">var</span>=<span class="value">"i"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">request</span>&gt;</span> <span class="tag">&lt;<span class="title">http</span> <span class="attribute">url</span>=<span class="value">"/test.txt"</span> <span class="attribute">method</span>=<span class="value">"GET"</span> <span class="attribute">version</span>=<span class="value">"1.1"</span>/&gt;</span> <span class="tag">&lt;/<span class="title">request</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">for</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">session</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">sessions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">tsung</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>刚开始的时候有很多东西要理解，但你一旦理解了它们后就会变得很简单。</p>
<p><client> 只是简单地指定了运行 Tsung 的主机。你可以指定 Tsung 使用的 IP 和 CPU 的最大数。你可以使用 maxusers 设置节点能够模拟的用户数量上限。每一个用户都会执行我们之后定义的操作。</client></p>
<p><servers> 指定了你要测试的 HTTP 服务器。我们可以使用这个选项去测试一个 IP 集群，或者一个单一的服务器。</servers></p>
<p><load> 定义了我们的模拟用户将会在什么时候“到达”我们的网站。以及它们达到的有多快。</load></p>
<p><arrivalphase> 在持续了 10 分钟的第一个阶段里，以 每秒 8 个用户的速率到达了 15,000 个用户。</arrivalphase></p>
<p><arrivalphase phase="”1″" duration="”10″" unit="”minute”"></arrivalphase></p>
<p><users maxnumber="”15000″" arrivalrate="”8″" unit="”second”/"><br>这里还有两个 arrivalphases，它们的用户都以同样的方式达到。<br>这些 arrivalphases 一起组成了一个 <load>，它控制了我们可以每秒产生多少个请求。</load></users></p>
<p><session> 这部分定义了一旦这些用户达到了你的网站，它们将会执行什么动作。<br>probability 允许你定义用户可能会做的随机事件。有时他们可能点击这里，有时他们可能点击那里。所有的Probability 加起来一定要等于 100% 。<br>在上面的配置里，用户只做一件事，所以它的 probability 等于 100% 。</session></p>
<p><for from="”1″" to="”10000000″" var="”i”"> 这就是用户在 100% 的时间里做的事情。它们循环遍历 10,000,000 次并且 <request> 一个网页：/test.txt 。<br>这个循环结构允许我们使用少量的用户连接去获取比较大的每秒请求数量。</request></for></p>
<p>一旦你已经很好地理解了它们，你就可以创建一个便利的别名，去快速观察 Tsung 报告。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc</span><br><span class="line"><span class="built_in">alias</span> treport=<span class="string">"/usr/lib/tsung/bin/tsung_stats.pl; firefox report.html"</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>然后启动 Tsung</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@loadnode1 ~] tsung <span class="operator"><span class="keyword">start</span></span><br><span class="line"><span class="keyword">Starting</span> Tsung</span><br><span class="line"><span class="string">"Log directory is: /root/.tsung/log/20120421-1004"</span></span></span><br></pre></td></tr></table></figure>
<p>结束后观察报告</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /root/.tsung/<span class="built_in">log</span>/<span class="number">20120421</span>-<span class="number">1004</span></span><br><span class="line">treport</span><br></pre></td></tr></table></figure>
<p><img src="/files/4.pic.jpg"></p>
<p>使用 Tsung 去规划你的集群构造</p>
<p>现在我们拥有了一个足够强大的负载测试工具，我们可以规划余下的集群构造了：</p>
<ol>
<li>使用 Tsung 去测试一个单一的 HTTP 服务器。获取一个基本的基准。</li>
<li>对 web 服务器进行调优，定期使用 Tsung 进行测试提高性能。</li>
<li>对这些系统的 TCP 套接字进行调优，获取最佳的网络性能。再来一次，测试，测试，不停地测试。</li>
<li>构造 LVS 集群，它包含了这些充分调优过的 web 服务器。</li>
<li>使用 Tsung IP 集群对 LVS 进行压力测试。</li>
</ol>
<p>在之后的两篇文章里，我将会向你展示如何使你的 web 服务器获取最高性能，以及怎样用 LVS 集群软件把它们整合起来。</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2015/11/10/Geode数据管理平台/" itemprop="url">
                Geode数据管理平台
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2015-11-10T21:23:08+08:00" content="2015-11-10">
            2015-11-10
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2015/11/10/Geode数据管理平台/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2015/11/10/Geode数据管理平台/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><h1 id="概述">概述</h1><p>Geode是一个提供实时、一致访问大型分布式云平台下数据密集型应用的数据管理平台。最近开源啦！</p>
<p>Geode 通过跨多进程，把内存、CPU、网络资源和可选的本地磁盘汇集起来，来管理应用程序对象及其行为。它使用动态复制和数据分片技术，来实现高可用性，改善性能、可伸缩性和容错。Geode 除了是一个分布式数据容器，它还是一个内存数据管理系统，提供了可靠的异步事件通知和有保证的消息传递。</p>
<p>Geode 是一个非常成熟、健壮的产品，它的前身可以追溯到第一个由 Smalltalk 构造的对象数据库：GeoStone。作为一个事务性、低延迟的数据引擎，多个华尔街交易平台首次将 Geode（称为GemFire™）部署在金融部门。如今已有超过 600 家企业用户将 Geode 用于大规模、7*24 业务核心应用程序中。其中一个应用案例就是中国国家铁路将 Geode 用于整个国家的铁路票务系统，10 个节点集群管理着 2TB 的内存热数据，以及 10 个备份节点作为高可用性和弹性扩展。</p>
<h1 id="主要概念和组件">主要概念和组件</h1><p>在 Geode 分布式系统中，“缓存”是用来形容一个节点的抽象概念。</p>
<p>在每个缓存中，由您定义数据区域。数据区域（Data region）类似于关系型数据库的表，并且作为“name/value 对”以分布式方式管理数据。复制区域（replicated region）存储着 {分布式系统中每个缓存成员数据的} 相同副本。分区区域（partitioned region）在缓存成员之间传播数据。系统配置之后，客户端应用 {在不了解底层系统架构的情况下} 也可访问区域中的分布式数据。当数据发生改变的时候，您可以定义监听器来接收通知，并且您也可以定义过期条件，来删除区域中的过期数据。</p>
<p>定位器（Locator）提供发现服务和负载均衡服务。您可通过定位器服务列表来配置客户端，定位器维护着一个动态成员服务器列表。默认情况下，Geode 客户端和服务器使用40404端口，以及通过使用多播互相通信。</p>
<p>Geode 包含以下特性：</p>
<ul>
<li><p>结合冗余、复制和“非共享”的持久化架构，来实现故障安全可靠性（译者解释：高可用，防止单点故障）和性能。</p>
</li>
<li><p>可水平扩展至成千上万个缓存成员，并结合多个缓存拓扑来满足不同的企业需求。该缓存可以分布在多个计算机中。</p>
</li>
<li><p>异步和同步缓存更新传播（propagation）。</p>
</li>
<li><p>Delta 仅在一个对象（delta）新旧不同版本之间传播，而不是整个对象，从而极大降低了分发成本。</p>
</li>
<li><p>可靠的异步事件通知，优化后的、低延迟的分布层保证了消息传递。</p>
</li>
<li><p>无需额外的硬件，应用程序即可提速 4~40 倍。</p>
</li>
<li><p>数据敏感和实时业务智能。如果在您检索时数据发生更改，您能立即看到数据的变化。</p>
</li>
<li><p>与 Spring 框架集成，以加速并简化可扩展的事务型企业应用程序的开发。</p>
</li>
<li><p>支持 JTA 事务。</p>
</li>
<li><p>整个集群范围的配置，可以持久化，并可导出到其他集群。</p>
</li>
<li><p>通过 HTTP 即可实现对集群远程管理。</p>
</li>
<li><p>为 REST 应用程序开发提供 REST API 支持。</p>
</li>
<li><p>在主版本发布之间滚动升级。</p>
</li>
</ul>
<h1 id="Geode_5分钟入门">Geode 5分钟入门</h1><p>从 Pivotal 获取源文件，从源文件中提取并构建（注：目前 Geode 支持 jdk1.7.75）：</p>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$ </span>cd geode</span><br><span class="line"><span class="variable">$ </span>./gradlew build installDist</span><br></pre></td></tr></table></figure>
<p>启动定位器和服务器：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ cd gemfire-assembly/build/<span class="operator"><span class="keyword">install</span>/geode</span><br><span class="line">$ ./<span class="keyword">bin</span>/gfsh</span><br><span class="line">gfsh&gt; <span class="keyword">start</span> <span class="keyword">locator</span> <span class="comment">--name=locator</span></span><br><span class="line">gfsh&gt; <span class="keyword">start</span> <span class="keyword">server</span> <span class="comment">--name=server</span></span></span><br></pre></td></tr></table></figure>
<p>创建一个区域：</p>
<figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">gfsh</span>&gt; <span class="comment">create</span> <span class="comment">region</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">name=region</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">type=REPLICATE</span></span><br></pre></td></tr></table></figure>
<p>编写一个客户端应用程序：</p>
<p>HelloWorld.java</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> com.gemstone.gemfire.cache.Region;</span><br><span class="line"><span class="keyword">import</span> com.gemstone.gemfire.cache.client.*;</span><br><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">HelloWorld</span> </span>&#123;</span><br><span class="line">public static <span class="keyword">void</span> main(<span class="built_in">String</span>[] args) throws Exception &#123;</span><br><span class="line">ClientCache cache = <span class="keyword">new</span> ClientCacheFactory()</span><br><span class="line">.addPoolLocator(<span class="string">"localhost"</span>, <span class="number">10334</span>)</span><br><span class="line">.create();</span><br><span class="line">Region&lt;<span class="built_in">String</span>, <span class="built_in">String</span>&gt; region = cache</span><br><span class="line">.&lt;<span class="built_in">String</span>, <span class="built_in">String</span>&gt;createClientRegionFactory(ClientRegionShortcut.CACHING_PROXY)</span><br><span class="line">.create(<span class="string">"region"</span>);</span><br><span class="line">region.put(<span class="string">"1"</span>, <span class="string">"Hello"</span>);</span><br><span class="line">region.put(<span class="string">"2"</span>, <span class="string">"World"</span>);</span><br><span class="line"><span class="keyword">for</span> (<span class="built_in">Map</span>.Entry&lt;<span class="built_in">String</span>, <span class="built_in">String</span>&gt; entry : region.entrySet()) &#123;</span><br><span class="line">System.out.format(<span class="string">"key = %s, value = %sn"</span>, entry.getKey(), entry.getValue());</span><br><span class="line">&#125;</span><br><span class="line">cache.close();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译并运行 HelloWorld.java。classpath 中应包含 gemfire-core-dependencies.jar 包：</p>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">javac -cp /some/path/geode/gemfire-assembly/build/install/geode/<span class="class"><span class="keyword">lib</span>/<span class="title">gemfire</span>-<span class="title">core</span>-<span class="title">dependencies</span>.<span class="title">jar</span> <span class="title">HelloWorld</span>.<span class="title">java</span></span></span><br><span class="line">java -cp .<span class="symbol">:/some/path/geode/gemfire-assembly/build/install/geode/lib/gemfire-core-dependencies</span>.jar <span class="constant">HelloWorld</span></span><br></pre></td></tr></table></figure>
<p>应用程序开发</p>
<p>Geode 应用程序可以用很多种客户端技术实现：</p>
<p>Java 通过使用 Geode 客户端 API，或者嵌入式使用 Geode API</p>
<p>Spring Data GemFire或 Spring Cache</p>
<p>Python（<a href="https://github.com/gemfire/py-gemfire-rest）" target="_blank" rel="external">https://github.com/gemfire/py-gemfire-rest）</a></p>
<p>REST</p>
<p>memcached<br>英文出处：Geode<br>译文出处：伯乐在线-Martin<br>译文链接：<a href="http://blog.jobbole.com/87810/" target="_blank" rel="external">http://blog.jobbole.com/87810/</a></p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2015/10/10/nginx 的 Basic Auth 认证/" itemprop="url">
                使用nginx 实现Basic Auth认证
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2015-10-10T10:13:57+08:00" content="2015-10-10">
            2015-10-10
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2015/10/10/nginx 的 Basic Auth 认证/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2015/10/10/nginx 的 Basic Auth 认证/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><h3 id="以centos_系统为例:">以centos 系统为例:</h3><p>添加httpd-tools工具<br><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y <span class="keyword">install</span> httpd-tools</span><br></pre></td></tr></table></figure></p>
<p>修改nginx 配置文件<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi <span class="regexp">/etc/</span>nginx<span class="regexp">/conf.d/</span><span class="keyword">default</span>.conf</span><br></pre></td></tr></table></figure></p>
<p>在server内增加<br><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">location</span> /basic &#123;</span><br><span class="line">    <span class="title">auth_basic</span> <span class="string">"Basic Auth"</span>; </span><br><span class="line">    <span class="title">auth_basic_user_file</span> <span class="string">"/etc/nginx/.htpasswd"</span>; </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p>
<p>创建一个用户 fedora 替换成你自己的账号，回车输入密码并确认<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">htpasswd -c /etc/nginx/<span class="class">.htpasswd</span> fedora</span><br></pre></td></tr></table></figure></p>
<p>重启nginx服务<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="regexp">/etc/</span>rc.d<span class="regexp">/init.d/</span>nginx restart</span><br></pre></td></tr></table></figure></p>
<p>或者<br><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">service</span> nginx reload</span><br></pre></td></tr></table></figure></p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">service</span> nginx restart</span><br></pre></td></tr></table></figure>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2015/08/26/struts2-modelDriven高级应用/" itemprop="url">
                struts2-modelDriven高级应用
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2015-08-26T21:33:59+08:00" content="2015-08-26">
            2015-08-26
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2015/08/26/struts2-modelDriven高级应用/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2015/08/26/struts2-modelDriven高级应用/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>struts2 modelDriven 高级应用</p>
<p><a href="https://travis-ci.org/izerui/struts2-advanced-modelDriven" target="_blank" rel="external"><img src="https://travis-ci.org/izerui/struts2-advanced-modelDriven.svg?branch=master" alt="Build Status"></a></p>
<p>#封装的第四种Action传参方式</p>
<p>##传统的struts传参有三种</p>
<ul>
<li><ol>
<li>通过属性传参</li>
</ol>
</li>
<li><ol>
<li>通过域模型传参</li>
</ol>
</li>
<li><ol>
<li>通过模型驱动传参数</li>
</ol>
</li>
</ul>
<p>##以上这三种各有利弊,总之一句话概括,无法完全的实现业务和参数分离.总得在自己的Action中定义相关的get set 方法.</p>
<p>希望能实现参数传递跟业务action完全分离.故封装了模型驱动参数获取方式.</p>
<p>#如此一来,action 还可以这样写:</p>
<p>-Action</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">YourAction</span> <span class="keyword">extends</span> <span class="title">BaseActionSupport</span>&lt;<span class="title">YourParam</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//TODO your code ....</span></span><br><span class="line">    <span class="comment">//在需要获取request参数的地方只需要通过 formParam对象get你需要的参数即可</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>-param class 就是一个简单的po类.随你写喽!</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">yourParam</span></span>&#123;</span><br><span class="line">    <span class="comment">// 各种 param fields</span></span><br><span class="line">    <span class="comment">// 各种 get set</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>#OK 所有的action请求,都会自动的封装到你定义的param类中. 前提这个类要有不带参数的构造方法,要有你希望获取的参数的get set 方法.</p>
<p>其实就是把action中的各种 get set 放到了一个统一的param类中.</p>
<p>一个action  一个 param类. 是不是很清晰.业务跟参数代码分离了. struts action 是不是更易读了.</p>
<h1 id="附:_顺带将_BaseActionSupport_放入了一个applicationContext">附: 顺带将 BaseActionSupport 放入了一个applicationContext</h1><h2 id="这样所有的action_都可以直接使用applicationContext_对象,如果您不喜欢可以自行去掉-">这样所有的action 都可以直接使用applicationContext 对象,如果您不喜欢可以自行去掉.</h2><p>##步骤如下:</p>
<ul>
<li><ol>
<li>删除 protected ApplicationContext applicationContext;</li>
</ol>
</li>
<li><ol>
<li>删除 applicationContext 的 set方法</li>
</ol>
</li>
<li><ol>
<li>去掉实现的接口 ApplicationContextAware</li>
</ol>
</li>
</ul>
<p>#不过建议留着吧.</p>
<ul>
<li>当你用上 spring 的event 的时候,你会需要它.</li>
<li>当你需要动态的根据className 或者 classType 获取bean 的时候,你会需要它.</li>
<li></li>
</ul>
<p><img src="http://dl.iteye.com/upload/picture/pic/130175/017e87c4-e4a6-3da8-92c6-7502a0e84486.png" alt="图"></p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2015/08/26/spring-boot监控/" itemprop="url">
                spring-boot监控
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2015-08-26T21:28:04+08:00" content="2015-08-26">
            2015-08-26
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2015/08/26/spring-boot监控/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2015/08/26/spring-boot监控/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><h1 id="spring-boot-actuator-monitor">spring-boot-actuator-monitor</h1><p>基于spring boot的 监控平台</p>
<p>#spring-boot-admin 监控后台</p>
<ol>
<li><p>新建一个maven工程 boot-admin ， 继承 spring-boot-starter-parent</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="title">parent</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>spring-boot-starter-parent<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="title">version</span>&gt;</span>1.2.4.RELEASE<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="title">parent</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>加入依赖</p>
</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="title">groupId</span>&gt;</span>de.codecentric<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>spring-boot-admin-server<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="title">version</span>&gt;</span>1.2.1<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="title">groupId</span>&gt;</span>de.codecentric<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>spring-boot-admin-server-ui<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="title">version</span>&gt;</span>1.2.1<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>spring-boot-starter-security<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="title">groupId</span>&gt;</span>com.googlecode.json-simple<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>json-simple<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="title">optional</span>&gt;</span>false<span class="tag">&lt;/<span class="title">optional</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol>
<li><p>加入plugin 以 exec jar包运行</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="title">plugin</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="title">executions</span>&gt;</span></span><br><span class="line">                 <span class="tag">&lt;<span class="title">execution</span>&gt;</span></span><br><span class="line">                     <span class="tag">&lt;<span class="title">goals</span>&gt;</span></span><br><span class="line">                         <span class="tag">&lt;<span class="title">goal</span>&gt;</span>repackage<span class="tag">&lt;/<span class="title">goal</span>&gt;</span></span><br><span class="line">                     <span class="tag">&lt;/<span class="title">goals</span>&gt;</span></span><br><span class="line">                     <span class="tag">&lt;<span class="title">configuration</span>&gt;</span></span><br><span class="line">                         <span class="tag">&lt;<span class="title">classifier</span>&gt;</span>exec<span class="tag">&lt;/<span class="title">classifier</span>&gt;</span></span><br><span class="line">                     <span class="tag">&lt;/<span class="title">configuration</span>&gt;</span></span><br><span class="line">                 <span class="tag">&lt;/<span class="title">execution</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;/<span class="title">executions</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;/<span class="title">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>新建执行执行类   com.izerui.boot.admin.Application.java</p>
</li>
</ol>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="annotation">@SpringBootApplication</span></span><br><span class="line"><span class="annotation">@EnableAdminServer</span></span><br><span class="line"><span class="annotation">@EnableDiscoveryClient</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Application</span> &#123;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="typename">void</span> main(String[] args) &#123;</span><br><span class="line">        SpringApplication.run(Application.<span class="keyword">class</span>,args);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li>声明监控后台的应用名称、端口、上下文、基本授权验证用户名、密码等信息  application.properties</li>
</ol>
<figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># application</span></span><br><span class="line">server.<span class="keyword">port</span> = <span class="number">8888</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># basic security</span></span><br><span class="line">security.ignored=/api/**</span><br><span class="line">security.<span class="keyword">user</span>.name=boot</span><br><span class="line">security.<span class="keyword">user</span>.password=boot1234</span><br></pre></td></tr></table></figure>
<ol>
<li><p>mvn install 后 执行 java -jar boot-admin-exec.jar</p>
</li>
<li><p>访问 <a href="http://主机ID:端口/boot-admin" target="_blank" rel="external">http://主机ID:端口/boot-admin</a></p>
</li>
</ol>
<hr>
<h1 id="注册应用到监控后台">注册应用到监控后台</h1><ol>
<li><p>确保应用继承 spring-boot-starter-parent</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="title">parent</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>spring-boot-starter-parent<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="title">version</span>&gt;</span>1.2.4.RELEASE<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="title">parent</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>引入依赖</p>
</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="title">groupId</span>&gt;</span>de.codecentric<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>spring-boot-admin-starter-client<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="title">version</span>&gt;</span>1.2.1<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="title">groupId</span>&gt;</span>com.googlecode.json-simple<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>json-simple<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="title">optional</span>&gt;</span>false<span class="tag">&lt;/<span class="title">optional</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol>
<li><p>配置被监控的应用的名称和监控后台地址 application.properties</p>
<blockquote>
<p>jar 方式运行</p>
</blockquote>
<h1 id="web_application">web application</h1><p>   server.port=28584<br>   info.version=@pom.version@<br>   info.info=微信代理服务<br>   management.context-path=/management<br>   server.context-path=/@pom.artifactId@<br>   endpoints.jmx.domain=@pom.artifactId@<br>   spring.application.name=@pom.artifactId@</p>
<h1 id="boot_admin">boot admin</h1><p>   spring.boot.admin.url=<a href="http://192.168.1.128:8888/boot-admin" target="_blank" rel="external">http://192.168.1.128:8888/boot-admin</a></p>
<hr>
<blockquote>
<p>war 方式运行</p>
</blockquote>
<h1 id="web_application-1">web application</h1><p>   info.version=@pom.version@<br>   info.info=阿里支付服务<br>   management.context-path=/management<br>   endpoints.jmx.domain=@pom.artifactId@<br>   spring.application.name=@pom.artifactId@</p>
<h1 id="boot_admin-1">boot admin</h1><p>   spring.boot.admin.url=<a href="http://192.168.1.128:8888" target="_blank" rel="external">http://192.168.1.128:8888</a><br>   spring.boot.admin.client.service-url=<a href="http://192.168.1.106:8098/qq-pay-web" target="_blank" rel="external">http://192.168.1.106:8098/qq-pay-web</a></p>
</li>
</ol>
<pre><code>注意： 别忘了添加logging配置
<span class="comment"># LOGGING</span>
logging.<span class="type">file</span>=/tmp/logs/offline-proxy-tcp.<span class="command">log</span>

注意： 有些应用被权限框架拦截了。故需要加入 
management.context-path=/management 
并在权限框架内 将 /management/** = anon 权限放开，声明url注意上下文。
</code></pre><ol>
<li><p>配置logback的jmx接口调用</p>
<figure class="highlight nimrod"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=<span class="string">"1.0"</span> encoding=<span class="string">"UTF-8"</span>?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;<span class="keyword">include</span> resource=<span class="string">"org/springframework/boot/logging/logback/base.xml"</span>/&gt;</span><br><span class="line">    &lt;jmxConfigurator/&gt;</span><br><span class="line">    &lt;logger name=<span class="string">"com.izerui"</span> level=<span class="string">"DEBUG"</span>/&gt;</span><br><span class="line">    &lt;root level=<span class="string">"INFO"</span>&gt;</span><br><span class="line">        &lt;appender-<span class="keyword">ref</span> <span class="keyword">ref</span>=<span class="string">"CONSOLE"</span> /&gt;</span><br><span class="line">        &lt;appender-<span class="keyword">ref</span> <span class="keyword">ref</span>=<span class="string">"FILE"</span> /&gt;</span><br><span class="line">    &lt;/root&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>发布自定义jmx接口</p>
</li>
</ol>
<pre><code>在spring bean 类的头信息上增加注解 @<span class="function"><span class="title">ManagedResource</span><span class="params">(currencyTimeLimit = <span class="number">20</span>)</span></span> 和 @Lazy

声明属性： @<span class="function"><span class="title">ManagedAttribute</span><span class="params">(description = <span class="string">"当前TCP连接数"</span>)</span></span>

声明方法： @<span class="function"><span class="title">ManagedOperation</span><span class="params">(description = <span class="string">"关闭对应IP的所有连接"</span>)</span></span>
          @ManagedOperationParameters(
            @<span class="function"><span class="title">ManagedOperationParameter</span><span class="params">(name = <span class="string">"ip"</span>, description = <span class="string">"终端IP"</span>)</span></span>
          )
</code></pre><p>参考资料：</p>
<ul>
<li><p><a href="https://github.com/codecentric/spring-boot-admin.git" target="_blank" rel="external">https://github.com/codecentric/spring-boot-admin.git</a></p>
</li>
<li><p><a href="http://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-jmx.html" target="_blank" rel="external">http://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-jmx.html</a></p>
</li>
<li><p><a href="https://github.com/spring-projects/spring-boot/tree/master/spring-boot-actuator" target="_blank" rel="external">https://github.com/spring-projects/spring-boot/tree/master/spring-boot-actuator</a></p>
</li>
<li><p><a href="http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#_auto_configured_healthindicators" target="_blank" rel="external">http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#_auto_configured_healthindicators</a></p>
</li>
</ul>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2015/08/26/基于redis的cas ticket共享/" itemprop="url">
                基于redis的cas ticket共享
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2015-08-26T21:18:26+08:00" content="2015-08-26">
            2015-08-26
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2015/08/26/基于redis的cas ticket共享/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2015/08/26/基于redis的cas ticket共享/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><h1 id="实现cas_ticket基于redis的集群">实现cas ticket基于redis的集群</h1><h3 id="目的">目的</h3><pre><code>克服cas单点故障，将cas认证请求分发到多台cas服务器上，降低负载。
</code></pre><h3 id="实现思路：">实现思路：</h3><pre><code>采用统一的ticket存取策略，所有ticket的操作都从中央缓存redis中存取。
采用session共享，session的存取都从中央缓存redis中存取。
</code></pre><h3 id="前提：">前提：</h3><pre><code>这里只讲解如何实现cas ticket的共享，关于session的共享请移步：
</code></pre><ul>
<li><a href="https://github.com/izerui/tomcat-redis-session-manager" target="_blank" rel="external">https://github.com/izerui/tomcat-redis-session-manager</a></li>
</ul>
<h3 id="实现步骤：">实现步骤：</h3><ol>
<li><p>基于cas源码 新增模块 <strong>cas-server-integration-redis</strong></p>
<p> pom.xml 文件如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="pi">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">project</span> <span class="attribute">xmlns</span>=<span class="value">"http://maven.apache.org/POM/4.0.0"</span></span><br><span class="line">	 <span class="attribute">xmlns:xsi</span>=<span class="value">"http://www.w3.org/2001/XMLSchema-instance"</span></span><br><span class="line">	 <span class="attribute">xsi:schemaLocation</span>=<span class="value">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">parent</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>cas-server<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.jasig.cas<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">version</span>&gt;</span>4.0.2<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="title">parent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="title">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>cas-server-integration-redis<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="title">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.jasig.cas<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>cas-server-core<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="title">version</span>&gt;</span>$&#123;project.version&#125;<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.jasig.cas<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>cas-server-support-saml<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="title">version</span>&gt;</span>$&#123;project.version&#125;<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="title">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="title">scope</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="comment">&lt;!-- redis --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.springframework.data<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>spring-data-redis<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="title">version</span>&gt;</span>1.5.1.RELEASE<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.apache.commons<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>commons-pool2<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="title">version</span>&gt;</span>2.2<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="title">groupId</span>&gt;</span>redis.clients<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>jedis<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="title">version</span>&gt;</span>2.6.2<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="title">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="title">project</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>添加类到 <strong>cas-server-integration-redis</strong> 模块的 org.jasig.cas.ticket.registry 包下</p>
<p> <strong>RedisTicketRegistry.java</strong></p>
</li>
</ol>
<figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span><br><span class="line"> * Licensed to Jasig under one or more contributor license</span><br><span class="line"> * agreements. See the NOTICE file distributed with this work</span><br><span class="line"> * for additional information regarding copyright ownership.</span><br><span class="line"> * Jasig licenses this file to you under the Apache License,</span><br><span class="line"> * Version 2.0 (the "License"); you may not use this file</span><br><span class="line"> * except in compliance with the License.  You may obtain a</span><br><span class="line"> * copy of the License at the following location:</span><br><span class="line"> *</span><br><span class="line"> *   http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"> *</span><br><span class="line"> * Unless required by applicable law or agreed to in writing,</span><br><span class="line"> * software distributed under the License is distributed on an</span><br><span class="line"> * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY</span><br><span class="line"> * KIND, either express or implied.  See the License for the</span><br><span class="line"> * specific language governing permissions and limitations</span><br><span class="line"> * under the License.</span><br><span class="line"> */</span></span><br><span class="line"><span class="keyword">package</span> org.jasig.cas.ticket.registry;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.jasig.cas.ticket.ServiceTicket;</span><br><span class="line"><span class="keyword">import</span> org.jasig.cas.ticket.Ticket;</span><br><span class="line"><span class="keyword">import</span> org.jasig.cas.ticket.TicketGrantingTicket;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.DisposableBean;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.validation.constraints.Min;</span><br><span class="line"><span class="keyword">import</span> javax.validation.constraints.NotNull;</span><br><span class="line"><span class="keyword">import</span> java.util.Collection;</span><br><span class="line"><span class="keyword">import</span> java.util.HashSet;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span><br><span class="line"> * Key-value ticket registry implementation that stores tickets in redis keyed on the ticket ID.</span><br><span class="line"> *</span><br><span class="line"> * <span class="doctag">@author</span> Scott Battaglia</span><br><span class="line"> * <span class="doctag">@author</span> Marvin S. Addison</span><br><span class="line"> * <span class="doctag">@since</span> 3.3</span><br><span class="line"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisTicketRegistry</span> <span class="keyword">extends</span> <span class="title">AbstractDistributedTicketRegistry</span> <span class="keyword">implements</span> <span class="title">DisposableBean</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> String TICKET_PREFIX = <span class="string">"TICKETGRANTINGTICKET:"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** redis client. */</span></span><br><span class="line">    <span class="annotation">@NotNull</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> TicketRedisTemplate client;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span><br><span class="line">     * TGT cache entry timeout in seconds.</span><br><span class="line">     */</span></span><br><span class="line">    <span class="annotation">@Min</span>(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> tgtTimeout;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span><br><span class="line">     * ST cache entry timeout in seconds.</span><br><span class="line">     */</span></span><br><span class="line">    <span class="annotation">@Min</span>(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> stTimeout;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span><br><span class="line">     * Creates a new instance using the given redis client instance, which is presumably configured via</span><br><span class="line">     * &lt;code&gt;net.spy.redis.spring.redisClientFactoryBean&lt;/code&gt;.</span><br><span class="line">     *</span><br><span class="line">     * <span class="doctag">@param</span> client                      redis client.</span><br><span class="line">     * <span class="doctag">@param</span> ticketGrantingTicketTimeOut TGT timeout in seconds.</span><br><span class="line">     * <span class="doctag">@param</span> serviceTicketTimeOut        ST timeout in seconds.</span><br><span class="line">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">RedisTicketRegistry</span><span class="params">(<span class="keyword">final</span> TicketRedisTemplate client, <span class="keyword">final</span> <span class="keyword">int</span> ticketGrantingTicketTimeOut,</span><br><span class="line">			       <span class="keyword">final</span> <span class="keyword">int</span> serviceTicketTimeOut)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">this</span>.tgtTimeout = ticketGrantingTicketTimeOut;</span><br><span class="line">	<span class="keyword">this</span>.stTimeout = serviceTicketTimeOut;</span><br><span class="line">	<span class="keyword">this</span>.client = client;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">protected</span> <span class="function"><span class="keyword">void</span> <span class="title">updateTicket</span><span class="params">(<span class="keyword">final</span> Ticket ticket)</span> </span>&#123;</span><br><span class="line">	logger.debug(<span class="string">"Updating ticket &#123;&#125;"</span>, ticket);</span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">	    <span class="keyword">this</span>.client.boundValueOps(TICKET_PREFIX+ticket.getId()).set(ticket,getTimeout(ticket), TimeUnit.SECONDS);</span><br><span class="line">	&#125; <span class="keyword">catch</span> (<span class="keyword">final</span> Exception e) &#123;</span><br><span class="line">	    logger.<span class="keyword">error</span>(<span class="string">"Failed updating &#123;&#125;"</span>, ticket, e);</span><br><span class="line">	&#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">addTicket</span><span class="params">(<span class="keyword">final</span> Ticket ticket)</span> </span>&#123;</span><br><span class="line">	logger.debug(<span class="string">"Adding ticket &#123;&#125;"</span>, ticket);</span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">	    <span class="keyword">this</span>.client.boundValueOps(TICKET_PREFIX+ticket.getId()).set(ticket,getTimeout(ticket),TimeUnit.SECONDS);</span><br><span class="line">	&#125;<span class="keyword">catch</span> (<span class="keyword">final</span> Exception e) &#123;</span><br><span class="line">	    logger.<span class="keyword">error</span>(<span class="string">"Failed adding &#123;&#125;"</span>, ticket, e);</span><br><span class="line">	&#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">boolean</span> <span class="title">deleteTicket</span><span class="params">(<span class="keyword">final</span> String ticketId)</span> </span>&#123;</span><br><span class="line">	logger.debug(<span class="string">"Deleting ticket &#123;&#125;"</span>, ticketId);</span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">	    <span class="keyword">this</span>.client.delete(TICKET_PREFIX+ticketId);</span><br><span class="line">	    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">	&#125; <span class="keyword">catch</span> (<span class="keyword">final</span> Exception e) &#123;</span><br><span class="line">	    logger.<span class="keyword">error</span>(<span class="string">"Failed deleting &#123;&#125;"</span>, ticketId, e);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="function">Ticket <span class="title">getTicket</span><span class="params">(<span class="keyword">final</span> String ticketId)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">	    <span class="keyword">final</span> Ticket t = (Ticket) <span class="keyword">this</span>.client.boundValueOps(TICKET_PREFIX+ticketId).get();</span><br><span class="line">	    <span class="keyword">if</span> (t != <span class="keyword">null</span>) &#123;</span><br><span class="line">		<span class="function"><span class="keyword">return</span> <span class="title">getProxiedTicketInstance</span><span class="params">(t)</span></span>;</span><br><span class="line">	    &#125;</span><br><span class="line">	&#125; <span class="keyword">catch</span> (<span class="keyword">final</span> Exception e) &#123;</span><br><span class="line">	    logger.<span class="keyword">error</span>(<span class="string">"Failed fetching &#123;&#125; "</span>, ticketId, e);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span><br><span class="line">     * &#123;<span class="doctag">@inheritDoc</span>&#125;</span><br><span class="line">     * This operation is not supported.</span><br><span class="line">     *</span><br><span class="line">     * <span class="doctag">@throws</span> UnsupportedOperationException if you try and call this operation.</span><br><span class="line">     */</span></span><br><span class="line">    <span class="annotation">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Collection&lt;Ticket&gt; getTickets() &#123;</span><br><span class="line">	Set&lt;Ticket&gt; tickets = <span class="keyword">new</span> HashSet&lt;Ticket&gt;();</span><br><span class="line">	Set&lt;String&gt; keys = <span class="keyword">this</span>.client.keys(TICKET_PREFIX + <span class="string">"*"</span>);</span><br><span class="line">	<span class="keyword">for</span> (String key:keys)&#123;</span><br><span class="line">	    Ticket ticket = <span class="keyword">this</span>.client.boundValueOps(TICKET_PREFIX+key).get();</span><br><span class="line">	    <span class="keyword">if</span>(ticket==<span class="keyword">null</span>)&#123;</span><br><span class="line">		<span class="keyword">this</span>.client.delete(TICKET_PREFIX+key);</span><br><span class="line">	    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">		tickets.add(ticket);</span><br><span class="line">	    &#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> tickets;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">	<span class="comment">//do nothing</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span><br><span class="line">     * <span class="doctag">@param</span> sync set to true, if updates to registry are to be synchronized</span><br><span class="line">     * <span class="doctag">@deprecated</span> As of version 3.5, this operation has no effect since async writes can cause registry consistency issues.</span><br><span class="line">     */</span></span><br><span class="line">    <span class="annotation">@Deprecated</span></span><br><span class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">setSynchronizeUpdatesToRegistry</span><span class="params">(<span class="keyword">final</span> <span class="keyword">boolean</span> sync)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="annotation">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="function"><span class="keyword">boolean</span> <span class="title">needsCallback</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">int</span> <span class="title">getTimeout</span><span class="params">(<span class="keyword">final</span> Ticket t)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (t <span class="keyword">instanceof</span> TicketGrantingTicket) &#123;</span><br><span class="line">	    <span class="keyword">return</span> <span class="keyword">this</span>.tgtTimeout;</span><br><span class="line">	&#125; <span class="function"><span class="keyword">else</span> <span class="title">if</span> <span class="params">(t <span class="keyword">instanceof</span> ServiceTicket)</span> </span>&#123;</span><br><span class="line">	    <span class="keyword">return</span> <span class="keyword">this</span>.stTimeout;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Invalid ticket type"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<pre><code><span class="keyword">*</span><span class="keyword">*</span>TicketRedisTemplate.java<span class="keyword">*</span><span class="keyword">*</span>
</code></pre><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.jasig.cas.ticket.registry;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.jasig.cas.ticket.<span class="type">Ticket</span>;</span><br><span class="line"><span class="keyword">import</span> org.springframework.data.redis.connection.<span class="type">RedisConnectionFactory</span>;</span><br><span class="line"><span class="keyword">import</span> org.springframework.data.redis.core.<span class="type">RedisTemplate</span>;</span><br><span class="line"><span class="keyword">import</span> org.springframework.data.redis.serializer.<span class="type">JdkSerializationRedisSerializer</span>;</span><br><span class="line"><span class="keyword">import</span> org.springframework.data.redis.serializer.<span class="type">RedisSerializer</span>;</span><br><span class="line"><span class="keyword">import</span> org.springframework.data.redis.serializer.<span class="type">StringRedisSerializer</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span><br><span class="line"> * Created by serv on 2015/7/19.</span><br><span class="line"> */</span></span><br><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">TicketRedisTemplate</span> <span class="keyword"><span class="keyword">extends</span></span> <span class="title">RedisTemplate&lt;String</span>, <span class="title">Ticket&gt;</span> &#123;</span></span><br><span class="line"></span><br><span class="line">    public <span class="type">TicketRedisTemplate</span>() &#123;</span><br><span class="line">	<span class="type">RedisSerializer</span>&lt;<span class="type">String</span>&gt; string = <span class="keyword">new</span> <span class="type">StringRedisSerializer</span>();</span><br><span class="line">	<span class="type">JdkSerializationRedisSerializer</span> jdk = <span class="keyword">new</span> <span class="type">JdkSerializationRedisSerializer</span>();</span><br><span class="line">	setKeySerializer(string);</span><br><span class="line">	setValueSerializer(jdk);</span><br><span class="line">	setHashKeySerializer(string);</span><br><span class="line">	setHashValueSerializer(jdk);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public <span class="type">TicketRedisTemplate</span>(<span class="type">RedisConnectionFactory</span> connectionFactory) &#123;</span><br><span class="line">	<span class="keyword">this</span>();</span><br><span class="line">	setConnectionFactory(connectionFactory);</span><br><span class="line">	afterPropertiesSet();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li><p><strong>cas-server-webapp</strong> 添加刚才新增模块的依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">groupId</span>&gt;</span>org.jasig.cas<span class="tag">&lt;/<span class="title">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">artifactId</span>&gt;</span>cas-server-integration-redis<span class="tag">&lt;/<span class="title">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">version</span>&gt;</span>$&#123;project.version&#125;<span class="tag">&lt;/<span class="title">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>修改 spring配置文件 <strong>cas-server-webapp</strong> 模块 WEB-INF\spring-configuration\ticketRegistry.xml</p>
<pre><code><span class="comment"><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;bean <span class="property">id</span>=<span class="string">"ticketRegistry"</span> <span class="type">class</span>=<span class="string">"org.jasig.cas.ticket.registry.DefaultTicketRegistry"</span> /&gt;</span><br></pre></td></tr></table></figure></span>
</code></pre><p> 替换为</p>
<pre><code><span class="comment"><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">bean</span> <span class="attribute">id</span>=<span class="value">"ticketRegistry"</span> <span class="attribute">class</span>=<span class="value">"org.jasig.cas.ticket.registry.RedisTicketRegistry"</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="title">constructor-arg</span> <span class="attribute">index</span>=<span class="value">"0"</span> <span class="attribute">ref</span>=<span class="value">"redisTemplate"</span> /&gt;</span></span><br><span class="line">	</span><br><span class="line">       <span class="comment">&lt;!-- TGT timeout in seconds --&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="title">constructor-arg</span> <span class="attribute">index</span>=<span class="value">"1"</span> <span class="attribute">value</span>=<span class="value">"1800"</span> /&gt;</span></span><br><span class="line">	</span><br><span class="line">       <span class="comment">&lt;!-- ST timeout in seconds --&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="title">constructor-arg</span> <span class="attribute">index</span>=<span class="value">"2"</span> <span class="attribute">value</span>=<span class="value">"300"</span> /&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="title">bean</span>&gt;</span></span><br><span class="line">	</span><br><span class="line">   <span class="tag">&lt;<span class="title">bean</span> <span class="attribute">id</span>=<span class="value">"jedisConnFactory"</span></span><br><span class="line">         <span class="attribute">class</span>=<span class="value">"org.springframework.data.redis.connection.jedis.JedisConnectionFactory"</span></span><br><span class="line">         <span class="attribute">p:hostName</span>=<span class="value">"192.168.1.89"</span></span><br><span class="line">         <span class="attribute">p:database</span>=<span class="value">"0"</span></span><br><span class="line">         <span class="attribute">p:usePool</span>=<span class="value">"true"</span>/&gt;</span></span><br><span class="line">	</span><br><span class="line">   <span class="tag">&lt;<span class="title">bean</span> <span class="attribute">id</span>=<span class="value">"redisTemplate"</span> <span class="attribute">class</span>=<span class="value">"org.jasig.cas.ticket.registry.TicketRedisTemplate"</span></span><br><span class="line">         <span class="attribute">p:connectionFactory-ref</span>=<span class="value">"jedisConnFactory"</span>/&gt;</span></span><br></pre></td></tr></table></figure></span>
</code></pre><p> 注意： 里面的 jedisConnFactory链接信息 修改为自己的连接串，这里选择database 1为存放cas票据的数据库</p>
</li>
</ol>
<ol>
<li><p>重新编译 mvn install </p>
<p>  生成的cas.war 部署到多个已经做过session共享的tomcat容器中。</p>
</li>
</ol>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">&raquo;</a>
  </nav>

 </div>

        

        
      </div>

      
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      <section class="site-overview">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <a href="https://github.com/izerui"><img class="site-author-image" src="https://avatars0.githubusercontent.com/u/1773233?v=3&s=460" alt="serv" itemprop="image"/></a>
          <p class="site-author-name" itemprop="name">serv</p>
        </div>
        <p class="site-description motion-element" itemprop="description">Spring Boot 分布式技术博客</p>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">15</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          <div class="site-state-item site-state-categories">
            
              <span class="site-state-item-count">0</span>
              <span class="site-state-item-name">分类</span>
              
          </div>

          <div class="site-state-item site-state-tags">
            <a href="/tags">
              <span class="site-state-item-count">33</span>
              <span class="site-state-item-name">标签</span>
              </a>
          </div>

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        <div class="links-of-author motion-element">
          
        </div>

      </section>

      

    </div>
  </aside>


    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner"> <div class="copyright" >
  
  &copy; &nbsp; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="icon-next-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">serv</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1256526924'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s95.cnzz.com/z_stat.php%3Fid%3D1256526924%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>

 </div>
    </footer>

    <div class="back-to-top"></div>
  </div>

  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  
  
    

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"izerui"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>
    
     

    
  
  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/fancy-box.js?v=0.4.5.1"></script>


  <script type="text/javascript" src="/js/helpers.js?v=0.4.5.1"></script>
  

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/js/motion_global.js?v=0.4.5.1" id="motion.global"></script>




  <script type="text/javascript" src="/js/nav-toggle.js?v=0.4.5.1"></script>
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  

  <script type="text/javascript">
    $(document).ready(function () {
      if (CONFIG.sidebar === 'always') {
        displaySidebar();
      }
      if (isMobile()) {
        FastClick.attach(document.body);
      }
    });
  </script>

  

  
  

  
  <script type="text/javascript" src="/js/lazyload.js"></script>
  <script type="text/javascript">
    $(function () {
      $("#posts").find('img').lazyload({
        placeholder: "/images/loading.gif",
        effect: "fadeIn"
      });
    });
  </script>
</body>
</html>
